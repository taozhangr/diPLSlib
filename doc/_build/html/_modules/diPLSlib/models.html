

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>diPLSlib.models &mdash; diPLSlib 2.4.2 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=e59714d7" />

  
      <script src="../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../_static/documentation_options.js?v=de1351e5"></script>
      <script src="../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            diPLSlib
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../diPLSlib.html">diPLSlib package</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">diPLSlib</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../index.html">Module code</a></li>
      <li class="breadcrumb-item active">diPLSlib.models</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for diPLSlib.models</h1><div class="highlight"><pre>
<span></span><span class="c1"># -*- coding: utf-8 -*-</span>
<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">diPLSlib model classes</span>

<span class="sd">- DIPLS base class</span>
<span class="sd">- GCTPLS class</span>
<span class="sd">&#39;&#39;&#39;</span>

<span class="c1"># Modules</span>
<span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">RegressorMixin</span>
<span class="kn">from</span> <span class="nn">sklearn.utils.validation</span> <span class="kn">import</span> <span class="n">check_array</span><span class="p">,</span> <span class="n">check_X_y</span>
<span class="kn">from</span> <span class="nn">sklearn.utils</span> <span class="kn">import</span> <span class="n">check_random_state</span>
<span class="kn">from</span> <span class="nn">sklearn.exceptions</span> <span class="kn">import</span> <span class="n">NotFittedError</span>
<span class="kn">from</span> <span class="nn">scipy.sparse</span> <span class="kn">import</span> <span class="n">issparse</span><span class="p">,</span> <span class="n">sparray</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">diPLSlib</span> <span class="kn">import</span> <span class="n">functions</span> <span class="k">as</span> <span class="n">algo</span>
<span class="kn">from</span> <span class="nn">diPLSlib.utils</span> <span class="kn">import</span> <span class="n">misc</span> <span class="k">as</span> <span class="n">helpers</span>
<span class="kn">import</span> <span class="nn">scipy.stats</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics.pairwise</span> <span class="kn">import</span> <span class="n">rbf_kernel</span><span class="p">,</span> <span class="n">linear_kernel</span>

<span class="c1"># Create KDAPLS class</span>

<div class="viewcode-block" id="KDAPLS">
<a class="viewcode-back" href="../../diPLSlib.html#diPLSlib.models.KDAPLS">[docs]</a>
<span class="k">class</span> <span class="nc">KDAPLS</span><span class="p">(</span><span class="n">RegressorMixin</span><span class="p">,</span> <span class="n">BaseEstimator</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Kernel Domain Adaptive Partial Least Squares (KDAPLS) algorithm for domain adaptation.</span>

<span class="sd">    This class implements KDAPLS by calling the &#39;kdapls&#39; function from &#39;functions.py&#39;.</span>
<span class="sd">    KDAPLS projects both source and target data into a reproducing kernel Hilbert space (RKHS) and aligns domains in that space while fitting the regression model on labeled data.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    A : int, default=2</span>
<span class="sd">        Number of latent variables to use in the model.</span>

<span class="sd">    l : float or tuple, default=0</span>
<span class="sd">        Regularization parameter. If a single value is provided, the same regularization is applied</span>
<span class="sd">        to all latent variables.</span>

<span class="sd">    kernel_params : dict, optional</span>
<span class="sd">        Dictionary specifying the kernel type and parameters. Accepted keys:</span>
<span class="sd">        - &quot;type&quot; : str, default=&quot;rbf&quot;</span>
<span class="sd">            Kernel type, can be &quot;rbf&quot;, &quot;linear&quot;, or &quot;primal&quot;.</span>
<span class="sd">        - &quot;gamma&quot; : float, default=0.0001</span>
<span class="sd">            Kernel coefficient for RBF kernels.</span>

<span class="sd">    target_domain : int, default=0</span>
<span class="sd">        Chooses which domain&#39;s coefficient vector is used for predictions.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    n_ : int</span>
<span class="sd">        Number of samples in `x`.</span>

<span class="sd">    n_features_in_ : int</span>
<span class="sd">        Number of features (variables) in `x`.</span>

<span class="sd">    ns_ : int</span>
<span class="sd">        Number of samples in `xs`.</span>

<span class="sd">    nt_ : int or list</span>
<span class="sd">        Number of samples in `xt`. If multiple target domains are provided, this is a list of sample counts for each domain.</span>

<span class="sd">    coef_ : ndarray of shape (n_features, 1)</span>
<span class="sd">        Regression coefficient vector used for predictions.</span>

<span class="sd">    X_ : ndarray of shape (n_, n_features_in_)</span>
<span class="sd">        Training data used for fitting the model.</span>

<span class="sd">    xs_ : ndarray of shape (ns_, n_features_in_)    </span>
<span class="sd">        (Unlabeled) Source domain data used for fitting the model.</span>

<span class="sd">    xt_ : ndarray of shape (nt_, n_features_in_)</span>
<span class="sd">        (Unlabeled) Target domain data used for fitting the model.</span>

<span class="sd">    y_mean_ : float</span>
<span class="sd">        Mean of the training response variable.</span>

<span class="sd">    centering_ : dict</span>
<span class="sd">        Dictionary of stored centering information for kernel operations.</span>

<span class="sd">    is_fitted_ : bool</span>
<span class="sd">        Whether the model has been fitted to data.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from diPLSlib.models import KDAPLS</span>
<span class="sd">    &gt;&gt;&gt; x = np.random.rand(100, 10)</span>
<span class="sd">    &gt;&gt;&gt; y = np.random.rand(100,1)</span>
<span class="sd">    &gt;&gt;&gt; xs = np.random.rand(80, 10)</span>
<span class="sd">    &gt;&gt;&gt; xt = np.random.rand(50, 10)</span>
<span class="sd">    &gt;&gt;&gt; model = KDAPLS(A=2, l=0.5, kernel_params={&quot;type&quot;:&quot;rbf&quot;,&quot;gamma&quot;:0.001})</span>
<span class="sd">    &gt;&gt;&gt; model.fit(x, y, xs, xt)</span>
<span class="sd">    KDAPLS(kernel_params={&#39;gamma&#39;: 0.001, &#39;type&#39;: &#39;rbf&#39;}, l=0.5)</span>
<span class="sd">    &gt;&gt;&gt; xtest = np.random.rand(5, 10)</span>
<span class="sd">    &gt;&gt;&gt; yhat = model.predict(xtest)</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    1. Huang, G., Chen, X., Li, L., Chen, X., Yuan, L., &amp; Shi, W. (2020). Domain adaptive partial least squares regression. </span>
<span class="sd">       Chemometrics and Intelligent Laboratory Systems, 201, 103986.</span>
<span class="sd">    2. B. Schölkopf, A. Smola, and K. Müller. Nonlinear component analysis as a kernel eigenvalue problem. </span>
<span class="sd">       Neural computation, 10(5):1299-1319, 1998.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">A</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">l</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">kernel_params</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">target_domain</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">A</span> <span class="o">=</span> <span class="n">A</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">l</span> <span class="o">=</span> <span class="n">l</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">kernel_params</span> <span class="o">=</span> <span class="n">kernel_params</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target_domain</span> <span class="o">=</span> <span class="n">target_domain</span>

<div class="viewcode-block" id="KDAPLS.fit">
<a class="viewcode-back" href="../../diPLSlib.html#diPLSlib.models.KDAPLS.fit">[docs]</a>
    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">xs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">xt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Fit the KDAPLS Model.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : np.ndarray</span>
<span class="sd">            Labeled source domain data (usually the same as xs).</span>
<span class="sd">        y : np.ndarray</span>
<span class="sd">            Corresponding labels for X.</span>
<span class="sd">        xs : np.ndarray</span>
<span class="sd">            Source domain data.</span>
<span class="sd">        xt : np.ndarray</span>
<span class="sd">            Target domain data.</span>
<span class="sd">        **kwargs : dict, optional</span>
<span class="sd">            Additional keyword arguments to pass to the model (e.g., for model selection purposes).</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        self : object</span>
<span class="sd">            Fitted estimator.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># Set kernel parameters</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel_params</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            
            <span class="n">kernel_params</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;primal&quot;</span><span class="p">}</span>

        <span class="k">else</span><span class="p">:</span>

            <span class="n">kernel_params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel_params</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

        
        <span class="c1"># Check for sparse input</span>
        <span class="k">if</span> <span class="n">issparse</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>

            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Sparse input is not supported. Please convert your data to dense format.&quot;</span><span class="p">)</span>
 
        <span class="c1"># Validate input arrays</span>
        <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">check_X_y</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">ensure_2d</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">allow_nd</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">accept_large_sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">accept_sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">force_all_finite</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        

        <span class="c1"># Check if source and target data are provided</span>
        <span class="k">if</span> <span class="n">xs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>

            <span class="n">xs</span> <span class="o">=</span> <span class="n">X</span>

        <span class="k">if</span> <span class="n">xt</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>

            <span class="n">xt</span> <span class="o">=</span> <span class="n">X</span>

        <span class="c1"># Validate source and target arrays</span>
        <span class="n">xs</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">ensure_2d</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">allow_nd</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">accept_large_sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">accept_sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">force_all_finite</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">xs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">atleast_2d</span><span class="p">(</span><span class="n">xs</span><span class="p">)</span> <span class="k">if</span> <span class="n">xs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">X</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">xt</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">xt</span> <span class="o">=</span> <span class="p">[</span><span class="n">check_array</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">ensure_2d</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">allow_nd</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">accept_large_sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">accept_sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">force_all_finite</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">xt</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">xt</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">xt</span><span class="p">,</span> <span class="n">ensure_2d</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">allow_nd</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">accept_large_sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">accept_sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">force_all_finite</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">xt</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">atleast_2d</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">xt</span><span class="p">]</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">xt</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">atleast_2d</span><span class="p">(</span><span class="n">xt</span><span class="p">)</span> <span class="k">if</span> <span class="n">xt</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">X</span>

        <span class="c1"># Check if at least two samples and features are provided</span>
        <span class="k">if</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;At least two samples are required to fit the model (got n_samples = </span><span class="si">{}</span><span class="s2">).&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
        
        <span class="k">if</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;KDAPLS requires at least 2 features to fit the model (got n_features = </span><span class="si">{}</span><span class="s2">).&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>


        <span class="c1"># Ensure y is 2D</span>
        <span class="k">if</span> <span class="n">y</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>


        <span class="c1"># Check for complex data</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">iscomplexobj</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="ow">or</span> <span class="n">np</span><span class="o">.</span><span class="n">iscomplexobj</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="ow">or</span> <span class="n">np</span><span class="o">.</span><span class="n">iscomplexobj</span><span class="p">(</span><span class="n">xs</span><span class="p">)</span> <span class="ow">or</span> <span class="n">np</span><span class="o">.</span><span class="n">iscomplexobj</span><span class="p">(</span><span class="n">xt</span><span class="p">):</span>
            
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Complex data not supported&quot;</span><span class="p">)</span>

        <span class="c1"># Preliminaries</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_features_in_</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ns_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">xs</span><span class="o">.</span><span class="n">shape</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">xt</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">nt_</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">xt</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">nt_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">xt</span><span class="o">.</span><span class="n">shape</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">y_</span> <span class="o">=</span> <span class="n">y</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">xs_</span> <span class="o">=</span> <span class="n">xs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">xt_</span> <span class="o">=</span> <span class="n">xt</span>


        <span class="n">b</span><span class="p">,</span> <span class="n">bst</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">Tst</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">P</span><span class="p">,</span> <span class="n">Pst</span><span class="p">,</span> <span class="n">E</span><span class="p">,</span> <span class="n">Est</span><span class="p">,</span> <span class="n">Ey</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">centering</span> <span class="o">=</span> <span class="n">algo</span><span class="o">.</span><span class="n">kdapls</span><span class="p">(</span>
            <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">xs</span><span class="p">,</span> <span class="n">xt</span><span class="p">,</span>
            <span class="n">A</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">A</span><span class="p">,</span>
            <span class="n">l</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">l</span><span class="p">,</span>
            <span class="n">kernel_params</span><span class="o">=</span><span class="n">kernel_params</span>
        <span class="p">)</span>

        <span class="c1"># Select coefficient vector based on target_domain</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_domain</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">coef_</span> <span class="o">=</span> <span class="n">b</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">coef_</span> <span class="o">=</span> <span class="n">bst</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">centering_</span> <span class="o">=</span> <span class="n">centering</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">target_domain</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">X_</span> <span class="o">=</span> <span class="n">X</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y_mean_</span> <span class="o">=</span> <span class="n">centering</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;y_mean_&quot;</span><span class="p">]</span> <span class="k">if</span> <span class="mi">0</span> <span class="ow">in</span> <span class="n">centering</span> <span class="k">else</span> <span class="mf">0.0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">is_fitted_</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">return</span> <span class="bp">self</span></div>


<div class="viewcode-block" id="KDAPLS.predict">
<a class="viewcode-back" href="../../diPLSlib.html#diPLSlib.models.KDAPLS.predict">[docs]</a>
    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Predict with KDAPLS model.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>

<span class="sd">        X : ndarray of shape (n_samples, n_features)</span>
<span class="sd">            Test data matrix to perform the prediction on.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>

<span class="sd">        yhat : ndarray of shape (n_samples_test,)</span>
<span class="sd">            Predicted response values for the test data.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Check if the model is fitted</span>
        <span class="n">check_is_fitted</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;is_fitted_&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">check_is_fitted</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">NotFittedError</span><span class="p">(</span><span class="s2">&quot;KDAPLS object is not fitted yet.&quot;</span><span class="p">)</span>
        
        <span class="c1"># Check for sparse input</span>
        <span class="k">if</span> <span class="n">issparse</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Sparse input is not supported. Please convert your data to dense format.&quot;</span><span class="p">)</span>

        <span class="c1"># Validate input array</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">ensure_2d</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">allow_nd</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">force_all_finite</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># Assert feature match</span>
        <span class="k">if</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Number of features in the test data (</span><span class="si">{</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">) does not match &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;the number of features in the training data (</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">X_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">).&quot;</span>
            <span class="p">)</span>

        <span class="n">Kt_c</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_x_centering</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">yhat</span> <span class="o">=</span> <span class="n">Kt_c</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">coef_</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">centering_</span><span class="p">[</span><span class="s2">&quot;y_mean_&quot;</span><span class="p">]</span>

        <span class="c1"># Ensure the shape of yhat matches the shape of y</span>
        <span class="n">yhat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ravel</span><span class="p">(</span><span class="n">yhat</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">yhat</span> </div>


    <span class="k">def</span> <span class="nf">_x_centering</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Center new data X using stored centering_.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>

<span class="sd">        X : ndarray of shape (n_samples, n_features)</span>
<span class="sd">            Test data matrix to perform the prediction on.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>

<span class="sd">        Kt : ndarray </span>
<span class="sd">            Centered test data matrix. The shape of Kt depends on the kernel type:</span>
<span class="sd">            - For &#39;rbf&#39; and &#39;linear&#39;, Kt is the kernel matrix between X and X_.</span>
<span class="sd">            - For &#39;primal&#39;, Kt is the centered test data matrix.</span>

<span class="sd">        &quot;&quot;&quot;</span>
    
        <span class="n">n</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">Kt</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># Check if X has same number of features as X_</span>
        <span class="k">if</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Number of features in the test data (</span><span class="si">{</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">) does not match &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;the number of features in the training data (</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">X_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">).&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel_params</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel_params</span><span class="p">[</span><span class="s2">&quot;type&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;rbf&quot;</span><span class="p">:</span>
                <span class="n">gamma_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel_params</span><span class="p">[</span><span class="s2">&quot;gamma&quot;</span><span class="p">]</span>
                <span class="n">Kt</span> <span class="o">=</span> <span class="n">rbf_kernel</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="n">gamma_</span><span class="p">)</span>

            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel_params</span><span class="p">[</span><span class="s2">&quot;type&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;linear&quot;</span><span class="p">:</span>
                <span class="n">Kt</span> <span class="o">=</span> <span class="n">linear_kernel</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_</span><span class="p">)</span>

            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel_params</span><span class="p">[</span><span class="s2">&quot;type&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;primal&quot;</span><span class="p">:</span>
                <span class="n">Kt</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Invalid kernel type. Supported types are &#39;rbf&#39;, &#39;linear&#39;, and &#39;primal&#39;.&quot;</span><span class="p">)</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel_params</span><span class="p">[</span><span class="s2">&quot;type&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;primal&quot;</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">Kt</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">centering_</span><span class="p">[</span><span class="s2">&quot;K&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        
            <span class="k">else</span><span class="p">:</span>

                <span class="n">J</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">n</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">n</span><span class="p">,</span> <span class="n">n</span><span class="p">))</span>
                <span class="n">Jt</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">centering_</span><span class="p">[</span><span class="s2">&quot;n&quot;</span><span class="p">])</span> <span class="o">*</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">))</span> <span class="o">@</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">centering_</span><span class="p">[</span><span class="s2">&quot;n&quot;</span><span class="p">])))</span>
                <span class="k">return</span> <span class="n">Kt</span> <span class="o">-</span> <span class="n">Kt</span> <span class="o">@</span> <span class="n">J</span> <span class="o">-</span> <span class="n">Jt</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">centering_</span><span class="p">[</span><span class="s2">&quot;K&quot;</span><span class="p">]</span> <span class="o">+</span> <span class="n">Jt</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">centering_</span><span class="p">[</span><span class="s2">&quot;K&quot;</span><span class="p">]</span> <span class="o">@</span> <span class="n">J</span>
        
        <span class="k">else</span><span class="p">:</span> <span class="c1"># Use primal da-PLS</span>

            <span class="n">Kt</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
            <span class="n">mean_vec</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">centering_</span><span class="p">[</span><span class="s2">&quot;K&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        
            <span class="k">return</span> <span class="n">Kt</span> <span class="o">-</span> <span class="n">mean_vec</span></div>



<div class="viewcode-block" id="DIPLS">
<a class="viewcode-back" href="../../diPLSlib.html#diPLSlib.models.DIPLS">[docs]</a>
<span class="k">class</span> <span class="nc">DIPLS</span><span class="p">(</span><span class="n">RegressorMixin</span><span class="p">,</span> <span class="n">BaseEstimator</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Domain-Invariant Partial Least Squares (DIPLS) algorithm for domain adaptation.</span>

<span class="sd">    This class implements the DIPLS algorithm, which is designed to align feature distributions </span>
<span class="sd">    across different domains while predicting the target variable `y`. It supports multiple </span>
<span class="sd">    source and target domains through domain-specific feature transformations.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    A : int</span>
<span class="sd">        Number of latent variables to be used in the model.</span>

<span class="sd">    l : float or tuple with len(l)=A, default=0</span>
<span class="sd">        Regularization parameter. If a single value is provided, the same regularization is applied to all latent variables.</span>

<span class="sd">    centering : bool, default=True</span>
<span class="sd">            If True, source and target domain data are mean-centered.</span>

<span class="sd">    heuristic : bool, default=False</span>
<span class="sd">        If True, the regularization parameter is set to a heuristic value that</span>
<span class="sd">        balances fitting the output variable y and minimizing domain discrepancy.</span>

<span class="sd">    target_domain : int, default=0</span>
<span class="sd">        If multiple target domains are passed, target_domain specifies</span>
<span class="sd">        for which of the target domains the model should apply. </span>
<span class="sd">        If target_domain=0, the model applies to the source domain,</span>
<span class="sd">        if target_domain=1, it applies to the first target domain, and so on.</span>

<span class="sd">    rescale : Union[str, ndarray], default=&#39;Target&#39;</span>
<span class="sd">            Determines rescaling of the test data. If &#39;Target&#39; or &#39;Source&#39;, the test data will be</span>
<span class="sd">            rescaled to the mean of xt or xs, respectively. If an ndarray is provided, the test data</span>
<span class="sd">            will be rescaled to the mean of the provided array.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>

<span class="sd">    n_ : int</span>
<span class="sd">        Number of samples in `x`.</span>

<span class="sd">    ns_ : int</span>
<span class="sd">        Number of samples in `xs`.</span>

<span class="sd">    nt_ : int</span>
<span class="sd">        Number of samples in `xt`.</span>

<span class="sd">    n_features_in_ : int</span>
<span class="sd">        Number of features (variables) in `x`.</span>

<span class="sd">    mu_ : ndarray of shape (n_features,)</span>
<span class="sd">        Mean of columns in `x`.</span>

<span class="sd">    mu_s_ : ndarray of shape (n_features,)</span>
<span class="sd">        Mean of columns in `xs`.</span>

<span class="sd">    mu_t_ : ndarray of shape (n_features,) or ndarray of shape (n_domains, n_features)</span>
<span class="sd">        Mean of columns in `xt`, averaged per target domain if multiple domains exist.</span>

<span class="sd">    b_ : ndarray of shape (n_features, 1)</span>
<span class="sd">        Regression coefficient vector.</span>

<span class="sd">    b0_ : float</span>
<span class="sd">        Intercept of the regression model.</span>

<span class="sd">    T_ : ndarray of shape (n_samples, A)</span>
<span class="sd">        Training data projections (scores).</span>

<span class="sd">    Ts_ : ndarray of shape (n_source_samples, A)</span>
<span class="sd">        Source domain projections (scores).</span>

<span class="sd">    Tt_ : ndarray of shape (n_target_samples, A)</span>
<span class="sd">        Target domain projections (scores).</span>

<span class="sd">    W_ : ndarray of shape (n_features, A)</span>
<span class="sd">        Weight matrix.</span>

<span class="sd">    P_ : ndarray of shape (n_features, A)</span>
<span class="sd">        Loadings matrix corresponding to x.</span>

<span class="sd">    Ps_ : ndarray of shape (n_features, A)</span>
<span class="sd">        Loadings matrix corresponding to xs.</span>

<span class="sd">    Pt_ : ndarray of shape (n_features, A)</span>
<span class="sd">        Loadings matrix corresponding to xt.</span>

<span class="sd">    E_ : ndarray of shape (n_source_samples, n_features)</span>
<span class="sd">        Residuals of source domain data.</span>

<span class="sd">    Es_ : ndarray of shape (n_source_samples, n_features)</span>
<span class="sd">        Source domain residual matrix.</span>

<span class="sd">    Et_ : ndarray of shape (n_target_samples, n_features)</span>
<span class="sd">        Target domain residual matrix.</span>

<span class="sd">    Ey_ : ndarray of shape (n_source_samples, 1)</span>
<span class="sd">        Residuals of response variable in the source domain.</span>

<span class="sd">    C_ : ndarray of shape (A, 1)</span>
<span class="sd">        Regression vector relating source projections to the response variable.</span>

<span class="sd">    opt_l_ : ndarray of shape (A, 1)</span>
<span class="sd">        Heuristically determined regularization parameter for each latent variable.</span>

<span class="sd">    discrepancy_ : ndarray</span>
<span class="sd">        The variance discrepancy between source and target domain projections.</span>

<span class="sd">    is_fitted_ : bool, default=False</span>
<span class="sd">        Whether the model has been fitted to data.</span>


<span class="sd">    References</span>
<span class="sd">    ----------</span>

<span class="sd">    1. Ramin Nikzad-Langerodi et al., &quot;Domain-Invariant Partial Least Squares Regression&quot;, Analytical Chemistry, 2018.</span>
<span class="sd">    2. Ramin Nikzad-Langerodi et al., &quot;Domain-Invariant Regression under Beer-Lambert&#39;s Law&quot;, Proc. ICMLA, 2019.</span>
<span class="sd">    3. Ramin Nikzad-Langerodi et al., Domain adaptation for regression under Beer–Lambert’s law, Knowledge-Based Systems, 2020.</span>
<span class="sd">    4. B. Mikulasek et al., &quot;Partial least squares regression with multiple domains&quot;, Journal of Chemometrics, 2023.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from diPLSlib.models import DIPLS</span>
<span class="sd">    &gt;&gt;&gt; x = np.random.rand(100, 10)</span>
<span class="sd">    &gt;&gt;&gt; y = np.random.rand(100,1)</span>
<span class="sd">    &gt;&gt;&gt; xs = np.random.rand(100, 10)</span>
<span class="sd">    &gt;&gt;&gt; xt = np.random.rand(50, 10)</span>
<span class="sd">    &gt;&gt;&gt; X = np.random.rand(10, 10)</span>
<span class="sd">    &gt;&gt;&gt; model = DIPLS(A=5, l=(10))</span>
<span class="sd">    &gt;&gt;&gt; model.fit(x, y, xs, xt)</span>
<span class="sd">    DIPLS(A=5, l=10)</span>
<span class="sd">    &gt;&gt;&gt; xtest = np.array([5, 7, 4, 3, 2, 1, 6, 8, 9, 10]).reshape(1, -1)</span>
<span class="sd">    &gt;&gt;&gt; yhat = model.predict(xtest)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">A</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">l</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">centering</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">heuristic</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">target_domain</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">rescale</span><span class="o">=</span><span class="s1">&#39;Target&#39;</span><span class="p">):</span>
        <span class="c1"># Model parameters</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">A</span> <span class="o">=</span> <span class="n">A</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">l</span> <span class="o">=</span> <span class="n">l</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">centering</span> <span class="o">=</span> <span class="n">centering</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">heuristic</span> <span class="o">=</span> <span class="n">heuristic</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target_domain</span> <span class="o">=</span> <span class="n">target_domain</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rescale</span> <span class="o">=</span> <span class="n">rescale</span>
        


<div class="viewcode-block" id="DIPLS.fit">
<a class="viewcode-back" href="../../diPLSlib.html#diPLSlib.models.DIPLS.fit">[docs]</a>
    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">xs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">xt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Fit the DIPLS model.</span>

<span class="sd">        This method fits the domain-invariant partial least squares (di-PLS) model</span>
<span class="sd">        using the provided source and target domain data. It can handle both single </span>
<span class="sd">        and multiple target domains.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : ndarray of shape (n_samples, n_features)</span>
<span class="sd">            Labeled input data from the source domain.</span>

<span class="sd">        y : ndarray of shape (n_samples, 1)</span>
<span class="sd">            Response variable corresponding to the input data `x`.</span>

<span class="sd">        xs : ndarray of shape (n_samples_source, n_features)</span>
<span class="sd">            Source domain X-data. If not provided, defaults to `X`.</span>

<span class="sd">        xt : Union[ndarray of shape (n_samples_target, n_features), List[ndarray]]</span>
<span class="sd">            Target domain X-data. Can be a single target domain or a list of arrays </span>
<span class="sd">            representing multiple target domains. If not provided, defaults to `X`.</span>

<span class="sd">        **kwargs : dict, optional</span>
<span class="sd">            Additional keyword arguments to pass to the model (e.g., </span>
<span class="sd">            for model selection purposes).</span>


<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        self : object</span>
<span class="sd">            Fitted model instance.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        
        <span class="c1"># Check for sparse input</span>
        <span class="k">if</span> <span class="n">issparse</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>

            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Sparse input is not supported. Please convert your data to dense format.&quot;</span><span class="p">)</span>
 
        <span class="c1"># Validate input arrays</span>
        <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">check_X_y</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">ensure_2d</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">allow_nd</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">accept_large_sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">accept_sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">force_all_finite</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        

        <span class="c1"># Check if source and target data are provided</span>
        <span class="k">if</span> <span class="n">xs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>

            <span class="n">xs</span> <span class="o">=</span> <span class="n">X</span>

        <span class="k">if</span> <span class="n">xt</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>

            <span class="n">xt</span> <span class="o">=</span> <span class="n">X</span>

        <span class="c1"># Validate source and target arrays</span>
        <span class="n">xs</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">ensure_2d</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">allow_nd</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">accept_large_sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">accept_sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">force_all_finite</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">xs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">atleast_2d</span><span class="p">(</span><span class="n">xs</span><span class="p">)</span> <span class="k">if</span> <span class="n">xs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">X</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">xt</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">xt</span> <span class="o">=</span> <span class="p">[</span><span class="n">check_array</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">ensure_2d</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">allow_nd</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">accept_large_sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">accept_sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">force_all_finite</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">xt</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">xt</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">xt</span><span class="p">,</span> <span class="n">ensure_2d</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">allow_nd</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">accept_large_sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">accept_sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">force_all_finite</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">xt</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">atleast_2d</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">xt</span><span class="p">]</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">xt</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">atleast_2d</span><span class="p">(</span><span class="n">xt</span><span class="p">)</span> <span class="k">if</span> <span class="n">xt</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">X</span>

        <span class="c1"># Flatten y to 1D array</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ravel</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

        <span class="c1"># Check for complex data</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">iscomplexobj</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="ow">or</span> <span class="n">np</span><span class="o">.</span><span class="n">iscomplexobj</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="ow">or</span> <span class="n">np</span><span class="o">.</span><span class="n">iscomplexobj</span><span class="p">(</span><span class="n">xs</span><span class="p">)</span> <span class="ow">or</span> <span class="n">np</span><span class="o">.</span><span class="n">iscomplexobj</span><span class="p">(</span><span class="n">xt</span><span class="p">):</span>
            
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Complex data not supported&quot;</span><span class="p">)</span>
        
        
        <span class="c1"># Check if source and target data are provided</span>
        <span class="k">if</span> <span class="n">xs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>

            <span class="n">xs</span> <span class="o">=</span> <span class="n">X</span>

        <span class="k">if</span> <span class="n">xt</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>

            <span class="n">xt</span> <span class="o">=</span> <span class="n">X</span>
        
        
        <span class="c1"># Preliminaries</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_features_in_</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ns_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">xs</span><span class="o">.</span><span class="n">shape</span>        
        
        <span class="bp">self</span><span class="o">.</span><span class="n">x_</span> <span class="o">=</span> <span class="n">X</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y_</span> <span class="o">=</span> <span class="n">y</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">xs_</span> <span class="o">=</span> <span class="n">xs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">xt_</span> <span class="o">=</span> <span class="n">xt</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">b0_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="p">)</span>

        <span class="c1"># Mean centering</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">centering</span><span class="p">:</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">mu_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">x_</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">mu_s_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">xs_</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">x_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">x_</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">mu_</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">xs_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">xs_</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">mu_s_</span>
            <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">b0_</span>

            <span class="c1"># Mutliple target domains</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">xt_</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
                
                <span class="bp">self</span><span class="o">.</span><span class="n">nt_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">xt</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">mu_t_</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">xt_</span><span class="p">]</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">xt_</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span> <span class="o">-</span> <span class="n">mu</span> <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">mu</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">xt_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">mu_t_</span><span class="p">)]</span>
            
            <span class="k">else</span><span class="p">:</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">nt_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">xt</span><span class="o">.</span><span class="n">shape</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">mu_t_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">xt_</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">xt_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">xt_</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">mu_t_</span>

        <span class="k">else</span><span class="p">:</span>

            <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_</span>
        

        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">x_</span> 
        <span class="n">xs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">xs_</span>
        <span class="n">xt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">xt_</span>

    
        <span class="c1"># Fit model</span>
        <span class="n">results</span> <span class="o">=</span> <span class="n">algo</span><span class="o">.</span><span class="n">dipals</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">xs</span><span class="p">,</span> <span class="n">xt</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">A</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">l</span><span class="p">,</span> <span class="n">heuristic</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">heuristic</span><span class="p">,</span> <span class="n">target_domain</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">target_domain</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">b_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">T_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">Ts_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">Tt_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">P_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">Ps_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">Pt_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">E_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">Es_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">Et_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">Ey_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">C_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">opt_l_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">discrepancy_</span> <span class="o">=</span> <span class="n">results</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">is_fitted_</span> <span class="o">=</span> <span class="kc">True</span>        
        <span class="k">return</span> <span class="bp">self</span></div>


            
<div class="viewcode-block" id="DIPLS.predict">
<a class="viewcode-back" href="../../diPLSlib.html#diPLSlib.models.DIPLS.predict">[docs]</a>
    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Predict y using the fitted DIPLS model.</span>

<span class="sd">        This method predicts the response variable for the provided test data using</span>
<span class="sd">        the fitted domain-invariant partial least squares (di-PLS) model.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>

<span class="sd">        X : ndarray of shape (n_samples, n_features)</span>
<span class="sd">            Test data matrix to perform the prediction on.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>

<span class="sd">        yhat : ndarray of shape (n_samples_test,)</span>
<span class="sd">            Predicted response values for the test data.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;is_fitted_&#39;</span><span class="p">)</span> <span class="ow">or</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_fitted_</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">NotFittedError</span><span class="p">(</span><span class="s2">&quot;This DIPLS instance is not fitted yet. Call &#39;fit&#39; with appropriate arguments before using this estimator.&quot;</span><span class="p">)</span>
        
        
        <span class="c1"># Check for sparse input</span>
        <span class="k">if</span> <span class="n">issparse</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Sparse input is not supported. Please convert your data to dense format.&quot;</span><span class="p">)</span>

        <span class="c1"># Validate input array</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">ensure_2d</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">allow_nd</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">force_all_finite</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        
        <span class="c1"># Rescale Test data </span>
        <span class="k">if</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rescale</span><span class="p">)</span> <span class="ow">is</span> <span class="nb">str</span><span class="p">):</span>

            <span class="k">if</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rescale</span> <span class="o">==</span> <span class="s1">&#39;Target&#39;</span><span class="p">):</span>

                <span class="k">if</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">xt_</span><span class="p">)</span> <span class="ow">is</span> <span class="nb">list</span><span class="p">):</span>

                    <span class="k">if</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">target_domain</span><span class="o">==</span><span class="mi">0</span><span class="p">):</span>

                        <span class="n">Xtest</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="o">...</span><span class="p">,:]</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">mu_s_</span>

                    <span class="k">else</span><span class="p">:</span>

                        <span class="n">Xtest</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="o">...</span><span class="p">,:]</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">mu_t_</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">target_domain</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

                <span class="k">else</span><span class="p">:</span>

                    <span class="n">Xtest</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="o">...</span><span class="p">,:]</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">mu_t_</span>

            <span class="k">elif</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rescale</span> <span class="o">==</span> <span class="s1">&#39;Source&#39;</span><span class="p">):</span>

                <span class="n">Xtest</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="o">...</span><span class="p">,:]</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">mu_</span>

            <span class="k">elif</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rescale</span> <span class="o">==</span> <span class="s1">&#39;none&#39;</span><span class="p">):</span>

                <span class="n">Xtest</span> <span class="o">=</span> <span class="n">X</span>

        <span class="k">elif</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rescale</span><span class="p">)</span> <span class="ow">is</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>

             <span class="n">Xtest</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="o">...</span><span class="p">,:]</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rescale</span><span class="p">,</span><span class="mi">0</span><span class="p">)</span>

        <span class="k">else</span><span class="p">:</span> 

            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s1">&#39;rescale must either be Source, Target or a Dataset&#39;</span><span class="p">)</span>
            
        
        <span class="n">yhat</span> <span class="o">=</span> <span class="n">Xtest</span><span class="nd">@self</span><span class="o">.</span><span class="n">b_</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b0_</span>

        <span class="c1"># Ensure the shape of yhat matches the shape of y</span>
        <span class="n">yhat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ravel</span><span class="p">(</span><span class="n">yhat</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">yhat</span></div>
</div>




<span class="c1"># Create a separate class for GCT-PLS model inheriting from class model</span>
<div class="viewcode-block" id="GCTPLS">
<a class="viewcode-back" href="../../diPLSlib.html#diPLSlib.models.GCTPLS">[docs]</a>
<span class="k">class</span> <span class="nc">GCTPLS</span><span class="p">(</span><span class="n">DIPLS</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Graph-based Calibration Transfer Partial Least Squares (GCT-PLS).</span>

<span class="sd">    This method minimizes the distance betwee source (xs) and target (xt) domain data pairs in the latent variable space</span>
<span class="sd">    while fitting the response. </span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">     l : float or tuple with len(l)=A, default=0</span>
<span class="sd">        Regularization parameter. If a single value is provided, the same regularization is applied to all latent variables.</span>

<span class="sd">    centering : bool, default=True</span>
<span class="sd">        If True, source and target domain data are mean-centered before fitting.</span>
<span class="sd">        Centering can be crucial in adjusting data for more effective transfer learning.</span>

<span class="sd">    heuristic : bool, default=False</span>
<span class="sd">        If True, the regularization parameter is set to a heuristic value aimed</span>
<span class="sd">        at balancing model fitting quality for the response variable y while minimizing</span>
<span class="sd">        discrepancies between domain representations.</span>

<span class="sd">    rescale : Union[str, ndarray], default=&#39;Target&#39;</span>
<span class="sd">        Determines rescaling of the test data. If &#39;Target&#39; or &#39;Source&#39;, the test data will be rescaled to the mean of xt or xs, respectively. </span>
<span class="sd">        If an ndarray is provided, the test data will be rescaled to the mean of the provided array.</span>


<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>

<span class="sd">    n_ : int</span>
<span class="sd">        Number of samples in `x`.</span>

<span class="sd">    ns_ : int</span>
<span class="sd">        Number of samples in `xs`.</span>

<span class="sd">    nt_ : int</span>
<span class="sd">        Number of samples in `xt`.</span>

<span class="sd">    n_features_in_ : int</span>
<span class="sd">        Number of features (variables) in `x`.</span>

<span class="sd">    mu_ : ndarray of shape (n_features,)</span>
<span class="sd">        Mean of columns in `x`.</span>

<span class="sd">    mu_s_ : ndarray of shape (n_features,)</span>
<span class="sd">        Mean of columns in `xs`.</span>

<span class="sd">    mu_t_ : ndarray of shape (n_features,)</span>
<span class="sd">        Mean of columns in `xt`.</span>

<span class="sd">    b_ : ndarray of shape (n_features, 1)</span>
<span class="sd">        Regression coefficient vector.</span>

<span class="sd">    b0_ : float</span>
<span class="sd">        Intercept of the regression model.</span>

<span class="sd">    T_ : ndarray of shape (n_samples, A)</span>
<span class="sd">        Training data projections (scores).</span>

<span class="sd">    Ts_ : ndarray of shape (n_source_samples, A)</span>
<span class="sd">        Source domain projections (scores).</span>

<span class="sd">    Tt_ : ndarray of shape (n_target_samples, A)</span>
<span class="sd">        Target domain projections (scores).</span>

<span class="sd">    W_ : ndarray of shape (n_features, A)</span>
<span class="sd">        Weight matrix.</span>

<span class="sd">    P_ : ndarray of shape (n_features, A)</span>
<span class="sd">        Loadings matrix corresponding to x.</span>

<span class="sd">    Ps_ : ndarray of shape (n_features, A)</span>
<span class="sd">        Loadings matrix corresponding to xs.</span>

<span class="sd">    Pt_ : ndarray of shape (n_features, A)</span>
<span class="sd">        Loadings matrix corresponding to xt.</span>

<span class="sd">    E_ : ndarray of shape (n_source_samples, n_features)</span>
<span class="sd">        Residuals of source domain data.</span>

<span class="sd">    Es_ : ndarray of shape (n_source_samples, n_features)</span>
<span class="sd">        Source domain residual matrix.</span>

<span class="sd">    Et_ : ndarray of shape (n_target_samples, n_features)</span>
<span class="sd">        Target domain residual matrix.</span>

<span class="sd">    Ey_ : ndarray of shape (n_source_samples, 1)</span>
<span class="sd">        Residuals of response variable in the source domain.</span>

<span class="sd">    C_ : ndarray of shape (A, 1)</span>
<span class="sd">        Regression vector relating source projections to the response variable.</span>

<span class="sd">    opt_l_ : ndarray of shape (A, 1)</span>
<span class="sd">        Heuristically determined regularization parameter for each latent variable.</span>

<span class="sd">    discrepancy_ : ndarray</span>
<span class="sd">        The variance discrepancy between source and target domain projections.</span>

<span class="sd">    is_fitted_ : bool, default=False</span>
<span class="sd">        Whether the model has been fitted to data.</span>


<span class="sd">    References</span>
<span class="sd">    ----------</span>

<span class="sd">    Nikzad‐Langerodi, R., &amp; Sobieczky, F. (2021). Graph‐based calibration transfer. </span>
<span class="sd">    Journal of Chemometrics, 35(4), e3319.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from diPLSlib.models import GCTPLS</span>
<span class="sd">    &gt;&gt;&gt; x = np.random.rand(100, 10)</span>
<span class="sd">    &gt;&gt;&gt; y = np.random.rand(100, 1)</span>
<span class="sd">    &gt;&gt;&gt; xs = np.random.rand(80, 10)</span>
<span class="sd">    &gt;&gt;&gt; xt = np.random.rand(80, 10)</span>
<span class="sd">    &gt;&gt;&gt; model = GCTPLS(A=3, l=(2,5,7))</span>
<span class="sd">    &gt;&gt;&gt; model.fit(x, y, xs, xt)</span>
<span class="sd">    GCTPLS(A=3, l=(2, 5, 7))</span>
<span class="sd">    &gt;&gt;&gt; xtest = np.array([5, 7, 4, 3, 2, 1, 6, 8, 9, 10]).reshape(1, -1)</span>
<span class="sd">    &gt;&gt;&gt; yhat = model.predict(xtest)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">A</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">l</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">centering</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">heuristic</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">rescale</span><span class="o">=</span><span class="s1">&#39;Target&#39;</span><span class="p">):</span>
        <span class="c1"># Model parameters</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">A</span> <span class="o">=</span> <span class="n">A</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">l</span> <span class="o">=</span> <span class="n">l</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">centering</span> <span class="o">=</span> <span class="n">centering</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">heuristic</span> <span class="o">=</span> <span class="n">heuristic</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rescale</span> <span class="o">=</span> <span class="n">rescale</span>

        
<div class="viewcode-block" id="GCTPLS.fit">
<a class="viewcode-back" href="../../diPLSlib.html#diPLSlib.models.GCTPLS.fit">[docs]</a>
    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">xs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">xt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Fit the GCT-PLS model to data.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>

<span class="sd">        x : ndarray of shape (n_samples, n_features)</span>
<span class="sd">            Labeled input data from the source domain.</span>

<span class="sd">        y : ndarray of shape (n_samples, 1)</span>
<span class="sd">            Response variable corresponding to the input data `x`.</span>

<span class="sd">        xs : ndarray of shape (n_sample_pairs, n_features)</span>
<span class="sd">            Source domain X-data. If not provided, defaults to `X`.</span>

<span class="sd">        xt : ndarray of shape (n_sample_pairs, n_features)</span>
<span class="sd">            Target domain X-data. If not provided, defaults to `X`.</span>

<span class="sd">        **kwargs : dict, optional</span>
<span class="sd">            Additional keyword arguments to pass to the model (e.g., </span>
<span class="sd">            for model selection purposes).</span>
<span class="sd"> </span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>

<span class="sd">        self : object</span>
<span class="sd">            Fitted model instance.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Check for sparse input</span>
        <span class="k">if</span> <span class="n">issparse</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>

            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Sparse input is not supported. Please convert your data to dense format.&quot;</span><span class="p">)</span>

        <span class="c1"># Validate input arrays</span>
        <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">check_X_y</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">ensure_2d</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">allow_nd</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">accept_large_sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">accept_sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">force_all_finite</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        
        <span class="c1"># Check if source and target data are provided</span>
        <span class="k">if</span> <span class="n">xs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>

            <span class="n">xs</span> <span class="o">=</span> <span class="n">X</span>

        <span class="k">if</span> <span class="n">xt</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>

            <span class="n">xt</span> <span class="o">=</span> <span class="n">X</span>

        <span class="c1"># Validate source and target arrays</span>
        <span class="n">xs</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">ensure_2d</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">allow_nd</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">accept_large_sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">accept_sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">force_all_finite</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">xs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">atleast_2d</span><span class="p">(</span><span class="n">xs</span><span class="p">)</span> <span class="k">if</span> <span class="n">xs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">X</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">xt</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">xt</span> <span class="o">=</span> <span class="p">[</span><span class="n">check_array</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">ensure_2d</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">allow_nd</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">accept_large_sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">accept_sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">force_all_finite</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">xt</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">xt</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">xt</span><span class="p">,</span> <span class="n">ensure_2d</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">allow_nd</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">accept_large_sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">accept_sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">force_all_finite</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">xt</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">atleast_2d</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">xt</span><span class="p">]</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">xt</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">atleast_2d</span><span class="p">(</span><span class="n">xt</span><span class="p">)</span> <span class="k">if</span> <span class="n">xt</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">X</span>

        <span class="c1"># Flatten y to 1D array</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ravel</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

        <span class="c1"># Check for complex data</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">iscomplexobj</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="ow">or</span> <span class="n">np</span><span class="o">.</span><span class="n">iscomplexobj</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="ow">or</span> <span class="n">np</span><span class="o">.</span><span class="n">iscomplexobj</span><span class="p">(</span><span class="n">xs</span><span class="p">)</span> <span class="ow">or</span> <span class="n">np</span><span class="o">.</span><span class="n">iscomplexobj</span><span class="p">(</span><span class="n">xt</span><span class="p">):</span>
            
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Complex data not supported&quot;</span><span class="p">)</span>
        
        
        <span class="c1"># Check if source and target data are provided</span>
        <span class="k">if</span> <span class="n">xs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>

            <span class="n">xs</span> <span class="o">=</span> <span class="n">X</span>

        <span class="k">if</span> <span class="n">xt</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>

            <span class="n">xt</span> <span class="o">=</span> <span class="n">X</span>
        

        <span class="c1"># Preliminaries</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_features_in_</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ns_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">xs</span><span class="o">.</span><span class="n">shape</span>        
        <span class="bp">self</span><span class="o">.</span><span class="n">nt_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">xt</span><span class="o">.</span><span class="n">shape</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">ns_</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nt_</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;The number of samples in the source domain (ns) must be equal to the number of samples in the target domain (nt).&quot;</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">x_</span> <span class="o">=</span> <span class="n">X</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y_</span> <span class="o">=</span> <span class="n">y</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">xs_</span> <span class="o">=</span> <span class="n">xs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">xt_</span> <span class="o">=</span> <span class="n">xt</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">b0_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mu_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">x_</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mu_s_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">xs_</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mu_t_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">xt_</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

        <span class="c1"># Mean Centering</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">centering</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
            
            <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">x_</span><span class="p">[</span><span class="o">...</span><span class="p">,:]</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">mu_</span>
            <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">b0_</span>

        <span class="k">else</span><span class="p">:</span> 
            
            <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">x_</span>
            <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_</span>

        <span class="n">xs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">xs_</span>
        <span class="n">xt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">xt_</span>
            
        <span class="c1"># Fit model and store matrices</span>
        <span class="n">results</span> <span class="o">=</span> <span class="n">algo</span><span class="o">.</span><span class="n">dipals</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">xs</span><span class="p">,</span> <span class="n">xt</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">A</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">l</span><span class="p">,</span> <span class="n">heuristic</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">heuristic</span><span class="p">,</span> <span class="n">laplacian</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">b_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">T_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">Ts_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">Tt_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">P_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">Ps_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">Pt_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">E_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">Es_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">Et_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">Ey_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">C_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">opt_l_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">discrepancy_</span> <span class="o">=</span> <span class="n">results</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">is_fitted_</span> <span class="o">=</span> <span class="kc">True</span>  <span class="c1"># Set the is_fitted attribute to True</span>
        <span class="k">return</span> <span class="bp">self</span></div>
</div>



<div class="viewcode-block" id="EDPLS">
<a class="viewcode-back" href="../../diPLSlib.html#diPLSlib.models.EDPLS">[docs]</a>
<span class="k">class</span> <span class="nc">EDPLS</span><span class="p">(</span><span class="n">DIPLS</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&#39;&#39;&#39;</span>

<span class="sd">    :math:`(\epsilon, \delta)`-Differentially Private Partial Least Squares Regression.</span>


<span class="sd">    This class implements the  :math:`(\epsilon, \delta)`-Differentially Private Partial Least Squares (PLS) regression method by Nikzad-Langerodi et al. (2024, unpublished).</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    </span>
<span class="sd">    A: int</span>
<span class="sd">        Number of latent variables.</span>
<span class="sd">    </span>
<span class="sd">    epsilon : float</span>
<span class="sd">        Privacy loss parameter.</span>

<span class="sd">    delta : float, default=0.05</span>
<span class="sd">        Failure probability.</span>

<span class="sd">    centering : bool, default=True</span>
<span class="sd">            If True, the data will be centered before fitting the model.</span>

<span class="sd">    </span>
<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>

<span class="sd">    n_: int</span>
<span class="sd">        Number of samples in the training data.</span>

<span class="sd">    n_features_: int</span>
<span class="sd">        Number of features in the training data.</span>

<span class="sd">    x_mean_: array, shape (n_features,)</span>
<span class="sd">        Estimated mean of each feature.</span>

<span class="sd">    coef_: array, shape (n_features,)</span>
<span class="sd">        Estimated regression coefficients.</span>

<span class="sd">    y_mean_: float</span>
<span class="sd">        Estimated intercept.</span>

<span class="sd">    x_scores_: array, shape (n, A)</span>
<span class="sd">        X scores.</span>

<span class="sd">    x_loadings_: array, shape (n_features, A)</span>
<span class="sd">        X loadings.</span>

<span class="sd">    x_weights_: array, shape (n_features, A)</span>
<span class="sd">        X weights.</span>

<span class="sd">    y_loadings_: array, shape (n_features, A)</span>
<span class="sd">        Y loadings.</span>

<span class="sd">    is_fitted_: bool</span>
<span class="sd">        True if the model has been fitted.</span>


<span class="sd">    References</span>
<span class="sd">    ----------</span>

<span class="sd">    - R.Nikzad-Langerodi, et al. (2024). (epsilon,delta)-Differentially private partial least squares regression (2024, unpublished).</span>
<span class="sd">    - Balle, B., &amp; Wang, Y. X. (2018, July). Improving the gaussian mechanism for differential privacy: Analytical calibration and optimal denoising. In International Conference on Machine Learning (pp. 394-403). PMLR.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from diPLSlib.models import EDPLS</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; x = np.random.rand(100, 10)</span>
<span class="sd">    &gt;&gt;&gt; y = np.random.rand(100,1)</span>
<span class="sd">    &gt;&gt;&gt; model = EDPLS(A=5, epsilon=0.1, delta=0.01)</span>
<span class="sd">    &gt;&gt;&gt; model.fit(x, y)</span>
<span class="sd">    EDPLS(A=5, delta=0.01, epsilon=0.1)</span>
<span class="sd">    &gt;&gt;&gt; xtest = np.array([5, 7, 4, 3, 2, 1, 6, 8, 9, 10]).reshape(1, -1)</span>
<span class="sd">    &gt;&gt;&gt; yhat = model.predict(xtest)</span>
<span class="sd">    &#39;&#39;&#39;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">A</span><span class="p">:</span><span class="nb">int</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">epsilon</span><span class="p">:</span><span class="nb">float</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">delta</span><span class="p">:</span><span class="nb">float</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">centering</span><span class="p">:</span><span class="nb">bool</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="c1"># Model parameters</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">A</span> <span class="o">=</span> <span class="n">A</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span> <span class="o">=</span> <span class="n">epsilon</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">delta</span> <span class="o">=</span> <span class="n">delta</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">centering</span> <span class="o">=</span> <span class="n">centering</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random_state</span> <span class="o">=</span> <span class="n">random_state</span>


<div class="viewcode-block" id="EDPLS.fit">
<a class="viewcode-back" href="../../diPLSlib.html#diPLSlib.models.EDPLS.fit">[docs]</a>
    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Fit the EDPLS model.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array, shape (n_samples, n_features)</span>
<span class="sd">            Training data.</span>

<span class="sd">        y : array, shape (n_samples,)</span>
<span class="sd">            Target values.</span>

<span class="sd">        **kwargs : dict, optional</span>
<span class="sd">            Additional keyword arguments to pass to the model (e.g., </span>
<span class="sd">            for model selection purposes).</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>

<span class="sd">        self : object</span>
<span class="sd">           Fitted model instance.</span>

<span class="sd">        &#39;&#39;&#39;</span>

        <span class="c1">### Validate input data</span>
        <span class="c1"># Check for sparse input</span>
        <span class="k">if</span> <span class="n">issparse</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>

            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Sparse input is not supported. Please convert your data to dense format.&quot;</span><span class="p">)</span>
 
        <span class="c1"># Validate input arrays</span>
        <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">check_X_y</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">ensure_2d</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">allow_nd</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">accept_large_sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">accept_sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">force_all_finite</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
         
        <span class="c1"># Flatten y to 1D array</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ravel</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

        <span class="c1"># Check for complex entries</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">iscomplexobj</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="ow">or</span> <span class="n">np</span><span class="o">.</span><span class="n">iscomplexobj</span><span class="p">(</span><span class="n">y</span><span class="p">):</span>
            
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Complex data not supported&quot;</span><span class="p">)</span>
        
        
        <span class="c1">### Preliminaries</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_features_in_</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">x_</span> <span class="o">=</span> <span class="n">X</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y_</span> <span class="o">=</span> <span class="n">y</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y_mean_</span><span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="p">)</span>

        <span class="c1"># Mean centering</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">centering</span><span class="p">:</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">x_mean_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">x_</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">x_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">x_</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">x_mean_</span>
            <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_mean_</span>

        <span class="k">else</span><span class="p">:</span>

            <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_</span>


        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">x_</span> 

        <span class="c1">### Fit model</span>
        <span class="n">rng</span> <span class="o">=</span> <span class="n">check_random_state</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">)</span>
        <span class="n">results</span> <span class="o">=</span> <span class="n">algo</span><span class="o">.</span><span class="n">edpls</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">A</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span><span class="p">,</span> <span class="n">delta</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">delta</span><span class="p">,</span> <span class="n">rng</span><span class="o">=</span><span class="n">rng</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">coef_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">x_weights_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">x_loadings_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_loadings_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">x_scores_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">x_residuals_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_residuals_</span>  <span class="o">=</span> <span class="n">results</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">is_fitted_</span> <span class="o">=</span> <span class="kc">True</span> 

        <span class="k">return</span> <span class="bp">self</span></div>

    
    
<div class="viewcode-block" id="EDPLS.predict">
<a class="viewcode-back" href="../../diPLSlib.html#diPLSlib.models.EDPLS.predict">[docs]</a>
    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Predict y using the fitted EDPLS model.</span>

<span class="sd">        Parameters</span>

<span class="sd">        ----------</span>

<span class="sd">        x: numpy array of shape (n_samples_test, n_features)</span>
<span class="sd">            Test data matrix to perform the prediction on.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>

<span class="sd">        yhat: numpy array of shape (n_samples_test, )</span>
<span class="sd">            Predicted response values for the test data.</span>


<span class="sd">        &quot;&quot;&quot;</span>
        
        <span class="c1"># Check if the model has been fitted</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;is_fitted_&#39;</span><span class="p">)</span> <span class="ow">or</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_fitted_</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">NotFittedError</span><span class="p">(</span><span class="s2">&quot;This DIPLS instance is not fitted yet. Call &#39;fit&#39; with appropriate arguments before using this estimator.&quot;</span><span class="p">)</span>
        
        
        <span class="c1"># Check for sparse input</span>
        <span class="k">if</span> <span class="n">issparse</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Sparse input is not supported. Please convert your data to dense format.&quot;</span><span class="p">)</span>

        <span class="c1"># Validate input array</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">ensure_2d</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">allow_nd</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">force_all_finite</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>


        <span class="c1"># Center and scale x</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">centering</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="o">...</span><span class="p">,:]</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">x_mean_</span>

        <span class="c1"># Predict y</span>
        <span class="n">yhat</span> <span class="o">=</span> <span class="n">x</span><span class="nd">@self</span><span class="o">.</span><span class="n">coef_</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_mean_</span>

        <span class="c1"># Ensure the shape of yhat matches the shape of y</span>
        <span class="n">yhat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ravel</span><span class="p">(</span><span class="n">yhat</span><span class="p">)</span>


        <span class="k">return</span> <span class="n">yhat</span></div>

    
    <span class="k">def</span> <span class="nf">_more_tags</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Return tags for the estimator.</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;poor_score&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">}</span></div>

</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024, Ramin Nikzad-Langerodi.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>