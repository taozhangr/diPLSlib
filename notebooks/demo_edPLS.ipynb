{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 在玉米 NIR 数据上的 ($\\epsilon$, $\\delta$)-差分隐私 PLS\n",
    "\n",
    "作者: Ramin Nikzad-Langerodi\n",
    "\n",
    "本笔记本包含了 Ramin Nikzad-Langerodi, Du Nguyen Duy, Mohit Kumar 和 Mathab Alghasi (2024) 发表的论文 \"($\\epsilon, \\delta$)-Differentially Private Partial Least Squares Regression\" 的配套代码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T01:11:48.947600200Z",
     "start_time": "2026-01-07T01:11:48.486572500Z"
    }
   },
   "outputs": [],
   "source": [
    "# 导入\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as rmse, r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from chemotools.baseline import AirPls\n",
    "from chemotools.scatter import MultiplicativeScatterCorrection\n",
    "from chemotools.derivative import SavitzkyGolay\n",
    "\n",
    "# EDPLS\n",
    "from diPLSlib.models import EDPLS\n",
    "\n",
    "# 关闭警告\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据集\n",
    "我们将使用来自 Eigenvector Research Inc. 的玉米 (Corn) 数据集。该数据集包含在不同红外光谱仪上记录的玉米样品的 NIR 光谱，以及水分、油、蛋白质和淀粉含量。该数据集可在 https://www.eigenvector.com/data/Corn/ 获得。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T01:11:51.150727200Z",
     "start_time": "2026-01-07T01:11:51.132718100Z"
    }
   },
   "outputs": [],
   "source": [
    "# 加载数据\n",
    "data = sio.loadmat('../data/corn.mat')\n",
    "\n",
    "# 光谱和参考值\n",
    "X = data['m5spec'][0][0]['data']\n",
    "y = data['propvals'][0][0]['data'][:, 0].reshape(-1, 1)\n",
    "sy = np.std(y)\n",
    "\n",
    "# 波长\n",
    "wn = data['m5spec'][0][0][9][1][0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 准确度-隐私权衡\n",
    "\n",
    "使用不同的 $\\epsilon$ 值训练具有固定 LVs 数量的 $(\\epsilon, \\delta)$-差分隐私 PLS 模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 准备工作\n",
    "eps = [1, 10, 100]                             # epsilon 值\n",
    "bo = 0                                         # 用于绘图的基线偏移\n",
    "ncomps=10                                      # 组件数量\n",
    "\n",
    "# 结果数组\n",
    "EPS=[]\n",
    "\n",
    "# 将数据分割为训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "plt.figure(figsize=(12, 3))\n",
    "plt.subplot(131)\n",
    "\n",
    "# 循环遍历 epsilon 值\n",
    "for i in eps:\n",
    "    \n",
    "    m = EDPLS(ncomps, epsilon=i, delta=0.01)\n",
    "    m.fit(X_train, y_train)\n",
    "\n",
    "    # 计算 RMSEP\n",
    "    ypred = m.predict(X_test)\n",
    "\n",
    "    # 绘制回归系数\n",
    "    plt.plot(wn, m.coef_ + bo)\n",
    "\n",
    "    EPS.append(f'$\\epsilon = {i:.0e}$')\n",
    "    bo -= 5\n",
    "\n",
    "plt.legend(EPS)\n",
    "plt.xlabel('波长 (nm)')\n",
    "plt.ylabel('系数')\n",
    "plt.title('回归系数')\n",
    "\n",
    "\n",
    "### 准确度-隐私权衡\n",
    "plt.subplot(132)\n",
    "# 定义重复次数\n",
    "num_repetitions = 100\n",
    "\n",
    "eps = [0.1, 1, 5, 10, 100, 250, 700]\n",
    "\n",
    "# 初始化存储结果的数组\n",
    "rmsep_results = np.zeros((num_repetitions, len(eps)))\n",
    "\n",
    "# 重复实验 100 次\n",
    "for rep in range(num_repetitions):\n",
    "    \n",
    "    # 将数据分割为训练集和测试集\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "    RMSEP = []\n",
    "    for i, epsilon in enumerate(eps):\n",
    "        m = EDPLS(ncomps, epsilon=epsilon, delta=0.01)\n",
    "        m.fit(X_train, y_train)\n",
    "\n",
    "        # 计算 RMSEP\n",
    "        ypred = m.predict(X_test)\n",
    "        rmsep = np.sqrt(rmse(y_test, ypred))/sy\n",
    "        RMSEP.append(rmsep)\n",
    "\n",
    "    # 存储本次重复的结果\n",
    "    rmsep_results[rep, :] = RMSEP\n",
    "\n",
    "# 计算均值和标准误差\n",
    "rmsep_mean = np.mean(rmsep_results, axis=0)\n",
    "rmsep_std = np.std(rmsep_results, axis=0) / np.sqrt(num_repetitions)\n",
    "\n",
    "# 绘制结果\n",
    "default_colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "blue = default_colors[0]\n",
    "orange = default_colors[1]\n",
    "\n",
    "# 绘制 RMSEP\n",
    "r = plt.errorbar(eps, rmsep_mean, yerr=rmsep_std, fmt='o-', capsize=5, label='RMSEP', color=blue, mec='k')\n",
    "#r = plt.plot(eps, rmsep_mean, 'o-', label='RMSEP', color=blue, mec='k')\n",
    "plt.xlabel('隐私损失 $\\epsilon$')\n",
    "plt.ylabel(f'RMSEP/$\\sigma_y$')\n",
    "plt.title('RMSEP vs. $\\epsilon$')\n",
    "plt.semilogx()\n",
    "plt.semilogy()\n",
    "plt.title('准确度-隐私权衡')\n",
    "\n",
    "\n",
    "### 真实值 vs 预测值 (PLS 基线)\n",
    "plt.subplot(133)\n",
    "\n",
    "pls = PLSRegression(n_components=ncomps, scale=False)\n",
    "pls.fit(X_train, y_train)\n",
    "ypred = pls.predict(X_test)\n",
    "plt.scatter(y_test, ypred, edgecolors='k', label='PLS/' + f'R2P =' + str(np.round(r2_score(y_test, ypred),3)))\n",
    "\n",
    "# 计算 R2 分数\n",
    "r2p = r2_score(y_test, ypred)\t\n",
    "rmsep = np.sqrt(rmse(y_test, ypred))\n",
    "\n",
    "# 标注图表\n",
    "plt.annotate(f'#LVs = {ncomps}', (0.05, 0.8), xycoords='axes fraction')\n",
    "plt.annotate(f'R$^2$P = {r2p:.3f}', (0.05, 0.7), xycoords='axes fraction')\n",
    "plt.annotate(f'RMSEP = {rmsep:.3f}', (0.05, 0.6), xycoords='axes fraction')\n",
    "\n",
    "plt.plot([9.25, 11], [9.25, 11], 'k--')\n",
    "plt.xlabel('测量值')\n",
    "plt.ylabel('预测值')\n",
    "plt.title('测量值 vs. 预测值')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\epsilon$ 越小，隐私/噪声水平越高，但模型的准确度越低。右图显示了基线 PLS 模型（不带隐私保证）在测试集上的准确度。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 给定 $\\epsilon$ 和 $\\delta$ 下 LVs 数量的优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义 epsilon 值的范围\n",
    "epsilon_values = [1, 10, 100, 200, 500]\n",
    "delta = 0.001\n",
    "\n",
    "results = {}\n",
    "\n",
    "model = EDPLS(8, epsilon=1, delta=delta)\n",
    "\n",
    "# 定义参数网格\n",
    "param_grid = {\n",
    "    'A': np.arange(1, 20)\n",
    "}\n",
    "\n",
    "plt.figure(figsize=(12, 3))\n",
    "plt.subplot(131)\n",
    "# 循环遍历 epsilon 值\n",
    "for epsilon in epsilon_values:\n",
    "\n",
    "    # 使用当前 epsilon 初始化模型\n",
    "    model = EDPLS(8, epsilon=epsilon, delta=delta)\n",
    "\n",
    "    # 定义 GridSearchCV 对象\n",
    "    gs = GridSearchCV(model, param_grid, cv=10, scoring='neg_root_mean_squared_error')\n",
    "\n",
    "    # 拟合模型\n",
    "    gs.fit(X_train, y_train)\n",
    "\n",
    "    # 存储结果\n",
    "    results[epsilon] = {\n",
    "        'param_A': gs.cv_results_['param_A'],\n",
    "        'mean_test_score': gs.cv_results_['mean_test_score'],\n",
    "        'std_test_score': gs.cv_results_['std_test_score']\n",
    "    }\n",
    "\n",
    "\n",
    "# 绘制结果\n",
    "for epsilon in epsilon_values:\n",
    "    mean_rmse = np.sqrt(-results[epsilon]['mean_test_score'])\n",
    "    std_rmse = results[epsilon]['std_test_score']\n",
    "    epsilon_sci = \"{:.1e}\".format(epsilon)\n",
    "    #plt.errorbar(results[epsilon]['param_A'], mean_rmse, yerr=std_rmse, fmt='o-', label=f'$\\epsilon = {epsilon_sci}$', capsize=2.5, mec='k')\n",
    "    plt.plot(results[epsilon]['param_A'], mean_rmse, 'o-', label=f'$\\epsilon = {epsilon_sci}$', mec='k')\n",
    "\n",
    "# 与 PLS 比较\n",
    "param_grid = {\n",
    "    'n_components': np.arange(1, 20)\n",
    "}\n",
    "\n",
    "pls = GridSearchCV(PLSRegression(scale=False), param_grid, cv=10, scoring='neg_root_mean_squared_error')\n",
    "pls.fit(X_train, y_train)\n",
    "\n",
    "# 存储结果\n",
    "results_pls = {\n",
    "    'param_n_components': pls.cv_results_['param_n_components'],\n",
    "    'mean_test_score': pls.cv_results_['mean_test_score'],\n",
    "    'std_test_score': pls.cv_results_['std_test_score']\n",
    "}\n",
    "mean_rmse = np.sqrt(-results_pls['mean_test_score'])\n",
    "std_rmse = results_pls['std_test_score']\n",
    "plt.errorbar(results_pls['param_n_components'], mean_rmse, yerr=std_rmse, fmt='x-', capsize=2.5, mec='k', label='PLS')\n",
    "\n",
    "plt.xlabel('组件数量')\n",
    "plt.ylabel('RMSECV')\n",
    "plt.semilogy()\n",
    "plt.title('RMSECV vs. 潜变量数量')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "### epsilon = 200 的 EDPLS 模型\n",
    "epsilon = 10\n",
    "ncomps = int(np.argmin(-results[epsilon]['mean_test_score']) + 1)\n",
    "\n",
    "m = EDPLS(ncomps, epsilon=epsilon, delta=delta)\n",
    "m.fit(X_train, y_train)\n",
    "\n",
    "# 计算 RMSEP\n",
    "ypred = m.predict(X_test)\n",
    "rmsep = np.sqrt(rmse(y_test, ypred))\n",
    "r2p = r2_score(y_test, ypred)\n",
    "\n",
    "\n",
    "# 绘制回归系数\n",
    "plt.subplot(132)\n",
    "plt.plot(wn, m.coef_)\n",
    "plt.xlabel('波长 (nm)')\n",
    "plt.ylabel('系数')\n",
    "plt.title('回归系数')\n",
    "\n",
    "# 测量值 vs. 预测值图\n",
    "plt.subplot(133)\n",
    "plt.scatter(y_test, ypred, edgecolors='k')\n",
    "\n",
    "# 标注图表\n",
    "plt.annotate(f'$\\epsilon = {epsilon}$', (0.05, 0.9), xycoords='axes fraction')\n",
    "plt.annotate(f'#LVs = {ncomps}', (0.05, 0.8), xycoords='axes fraction')\n",
    "plt.annotate(f'R$^2$P = {r2p:.3f}', (0.05, 0.7), xycoords='axes fraction')\n",
    "plt.annotate(f'RMSEP = {rmsep:.3f}', (0.05, 0.6), xycoords='axes fraction')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', transform=plt.gca().transAxes)\n",
    "plt.xlabel('测量值')\n",
    "plt.ylabel('预测值')\n",
    "plt.title('测量值 vs. 预测值')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于隐私-准确度权衡度高，在原始玉米光谱上实现强隐私保证（即 $\\epsilon \\leq 1$）是困难的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 光谱预处理对隐私-准确度权衡的影响"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建预处理过的数据集\n",
    "airpls = AirPls()                                                           # 基线校正\n",
    "X_airpls = airpls.fit_transform(X)\n",
    "\n",
    "msc = MultiplicativeScatterCorrection()                                     # 乘性散射校正\n",
    "X_msc = msc.fit_transform(X)\n",
    "\n",
    "sg = SavitzkyGolay(window_size=25, polynomial_order=2, derivate_order=2)    # Savitzky-Golay 二阶导数\n",
    "X_sg = sg.fit_transform(X)\n",
    "\n",
    "datasets = {'AirPLS': X_airpls, 'MSC': X_msc, 'SG': X_sg}\n",
    "\n",
    "# 定义重复次数\n",
    "num_repetitions = 10\n",
    "\n",
    "eps = [0.1, 1, 1.5, 2, 5, 10]\n",
    "delta = 0.05\n",
    "ncomps = 7\n",
    "\n",
    "plt.figure(figsize=(12, 3))\n",
    "plt.subplot(131)\n",
    "\n",
    "for dataset_name, X_transformed in datasets.items():\n",
    "    # 初始化存储结果的数组\n",
    "    rmsep_results = np.zeros((num_repetitions, len(eps)))\n",
    "\n",
    "    # 重复实验 10 次\n",
    "    for rep in range(num_repetitions):\n",
    "        \n",
    "        # 将数据分割为训练集和测试集\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_transformed, y, test_size=0.3)\n",
    "\n",
    "        RMSEP = []\n",
    "        for i, epsilon in enumerate(eps):\n",
    "            m = EDPLS(ncomps, epsilon=epsilon, delta=delta)\n",
    "            m.fit(X_train, y_train)\n",
    "\n",
    "            # 计算 RMSEP\n",
    "            ypred = m.predict(X_test)\n",
    "            rmsep = np.sqrt(rmse(y_test, ypred))\n",
    "            RMSEP.append(rmsep)\n",
    "\n",
    "        # 存储本次重复的结果\n",
    "        rmsep_results[rep, :] = RMSEP\n",
    "\n",
    "# 计算均值和标准误差\n",
    "    rmsep_mean = np.mean(rmsep_results, axis=0)\n",
    "    rmsep_std = np.std(rmsep_results, axis=0) / np.sqrt(num_repetitions)\n",
    "\n",
    "    # 绘制结果\n",
    "    default_colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "    blue = default_colors[0]\n",
    "    orange = default_colors[1]\n",
    "\n",
    "    # 绘制 RMSEP\n",
    "    r = plt.errorbar(eps, rmsep_mean, yerr=rmsep_std, fmt=\"o-\", capsize=5, label=dataset_name, mec='k')\n",
    "\n",
    "\n",
    "plt.xlabel('隐私损失 $\\epsilon$')\n",
    "plt.ylabel('RMSEP')\n",
    "plt.title('RMSEP vs. $\\epsilon$')\n",
    "plt.semilogx()\n",
    "plt.semilogy()\n",
    "plt.title('准确度-隐私权衡')\n",
    "plt.legend()\n",
    "\n",
    "# 为所有数据集在 epsilon=1 下进行 GridSearchCV\n",
    "plt.subplot(132)\n",
    "\n",
    "epsilon=1\n",
    "\n",
    "results = {}\n",
    "model = EDPLS(8, epsilon=2, delta=delta)\n",
    "\n",
    "# 定义参数网格\n",
    "param_grid = {\n",
    "    'A': np.arange(1, 15)\n",
    "}\n",
    "\n",
    "# 循环遍历数据集\n",
    "for dataset_name, X_transformed in datasets.items():\n",
    "\n",
    "    # 将数据分割为训练集和测试集\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_transformed, y, test_size=0.3)\n",
    "\n",
    "    # 使用当前 epsilon 初始化模型\n",
    "    model = EDPLS(8, epsilon=epsilon, delta=delta)\n",
    "\n",
    "    # 定义 GridSearchCV 对象\n",
    "    gs = GridSearchCV(model, param_grid, cv=10, scoring='neg_root_mean_squared_error')\n",
    "\n",
    "    # 拟合模型\n",
    "    gs.fit(X_train, y_train)\n",
    "\n",
    "    # 存储结果\n",
    "    results[(dataset_name)] = {\n",
    "        'param_A': gs.cv_results_['param_A'],\n",
    "        'mean_test_score': gs.cv_results_['mean_test_score'],\n",
    "        'std_test_score': gs.cv_results_['std_test_score']\n",
    "}\n",
    "\n",
    "# 绘制结果\n",
    "for dataset_name in datasets.keys():\n",
    "\n",
    "    mean_rmse = np.sqrt(-results[(dataset_name)]['mean_test_score'])\n",
    "    std_rmse = results[(dataset_name)]['std_test_score']\n",
    "    plt.plot(results[(dataset_name)]['param_A'], mean_rmse, 'o-', label=f'{dataset_name}', mec='k')\n",
    "\n",
    "plt.xlabel('组件数量')\n",
    "plt.ylabel('RMSECV')\n",
    "plt.semilogy()\n",
    "plt.title('RMSECV vs. 潜变量数量')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "\n",
    "# 为 SG 数据集在 epsilon = 5 和最佳 LVs 数量下绘制测量值 vs 预测值\n",
    "plt.subplot(133)\n",
    "\n",
    "epsilon = 1\n",
    "ncomps = int(np.argmin(-results['SG']['mean_test_score']) + 1)\n",
    "\n",
    "m = EDPLS(ncomps, epsilon=epsilon, delta=delta)\n",
    "\n",
    "# 将数据分割为训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_sg, y, test_size=0.3) \n",
    "\n",
    "m.fit(X_train, y_train)\n",
    "ypred = m.predict(X_test)\n",
    "rmsep = np.sqrt(rmse(y_test, ypred))\n",
    "r2p = r2_score(y_test, ypred)\n",
    "\n",
    "plt.scatter(y_test, ypred, edgecolors='k', label=dataset_name)\n",
    "\n",
    "plt.plot([9.25, 11], [9.25, 11], 'k--')\n",
    "plt.xlabel('测量值')\n",
    "plt.ylabel('预测值')\n",
    "plt.title('测量值 vs. 预测值')\n",
    "\n",
    "# 标注图表\n",
    "plt.annotate(f'$\\epsilon = {epsilon}$', (0.05, 0.9), xycoords='axes fraction')\n",
    "plt.annotate(f'#LVs = {ncomps}', (0.05, 0.8), xycoords='axes fraction')\n",
    "plt.annotate(f'R$^2$P = {r2p:.3f}', (0.05, 0.7), xycoords='axes fraction')\n",
    "plt.annotate(f'RMSEP = {rmsep:.3f}', (0.05, 0.6), xycoords='axes fraction')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基于 Savitzky-Golay（一阶导数）的光谱预处理显著改善了隐私-准确度权衡。模型现在在具有合理准确度的同时表现出强隐私保证（$\\epsilon = 1$）。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
