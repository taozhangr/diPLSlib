{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (k)da-PLS 在域自适应中的应用\n",
    "## Dr. Ramin Nikzad-Langerodi\n",
    "### Bottleneck Analytics GmbH\n",
    "info@bottleneck-analytics.com\n",
    "\n",
    "___\n",
    "首先，我们加载一些将要使用的模块，包括 di-/da-PLS 类。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T01:11:48.947600200Z",
     "start_time": "2026-01-07T01:11:48.486572500Z"
    }
   },
   "outputs": [],
   "source": [
    "# 加载模块\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from diPLSlib.models import DIPLS as dipls\n",
    "from diPLSlib.models import KDAPLS as kdapls\n",
    "from diPLSlib.utils import misc as fct\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_predict\n",
    "\n",
    "# 配置中文绑图支持\n",
    "fct.setup_chinese_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模拟数据\n",
    "\n",
    "让我们创建一些模拟的“源域”和“目标域”数据集，分别包含 N=50 个样本和 p=100 个变量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T01:11:51.150727200Z",
     "start_time": "2026-01-07T01:11:51.132718100Z"
    }
   },
   "outputs": [],
   "source": [
    "n = 50  # 样本数量\n",
    "p = 100 # 变量数量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为此，我们定义了 3 个高斯函数，其中第一个对应于我们将尝试建模的（分析物）信号，另外两个对应于干扰信号（干扰物）。\n",
    "\n",
    "源域数据集将仅包含分析物信息以及两个干扰物中**一个**的贡献。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(10)\n",
    "\n",
    "# 源域 (分析物 + 1 种干扰物)\n",
    "S1 = fct.gengaus(p, 50, 15, 8, 0)  # 分析物信号\n",
    "S2 = fct.gengaus(p, 70, 10, 10, 0) # 干扰物 1 信号\n",
    "S = np.vstack([S1,S2])\n",
    "\n",
    "# 分析物和干扰物浓度\n",
    "Cs = 10*np.random.rand(n,2)\n",
    "\n",
    "# 光谱\n",
    "Xs = Cs@S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在目标域中，我们将有来自分析物和**两种**干扰物的贡献。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 目标域 (分析物 + 2 种干扰物)\n",
    "S1 = fct.gengaus(p, 50, 15, 8, 0)  # 分析物信号\n",
    "S2 = fct.gengaus(p, 70, 10, 10, 0) # 干扰物 1 信号\n",
    "S3 = fct.gengaus(p, 30, 10, 10, 0) # 干扰物 2 信号\n",
    "S = np.vstack([S1,S2,S3])\n",
    "\n",
    "# 分析物和干扰物浓度\n",
    "Ct = 10*np.random.rand(n,3)\n",
    "\n",
    "# 光谱\n",
    "Xt = Ct@S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "让我们绘制分析物和干扰物的纯信号以及模拟数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制纯信号\n",
    "plt.figure()\n",
    "\n",
    "plt.subplot(211)\n",
    "plt.plot(S1)\n",
    "plt.plot(S2)\n",
    "plt.plot(S3)\n",
    "plt.legend(['分析物','干扰物 1','干扰物 2'])\n",
    "plt.title('纯信号')\n",
    "plt.xlabel('X-变量')\n",
    "plt.ylabel('信号')\n",
    "plt.axvline(x=50,linestyle='-',color='k',alpha=0.5)\n",
    "plt.axvline(x=70,linestyle=':',color='k',alpha=0.5)\n",
    "plt.axvline(x=30,linestyle=':',color='k',alpha=0.5)\n",
    "\n",
    "# 源域\n",
    "plt.subplot(223)\n",
    "plt.plot(Xs.T, 'b', alpha=0.2)\n",
    "plt.title('源域')\n",
    "plt.xlabel('X-变量')\n",
    "plt.ylabel('信号')\n",
    "plt.axvline(x=50,linestyle='-',color='k',alpha=0.5)\n",
    "plt.axvline(x=70,linestyle=':',color='k',alpha=0.5)\n",
    "\n",
    "# 目标域\n",
    "plt.subplot(224)\n",
    "plt.plot(Xt.T, 'r', alpha=0.2)\n",
    "plt.title('目标域')\n",
    "plt.xlabel('X-变量')\n",
    "plt.ylabel('信号')\n",
    "plt.axvline(x=50,linestyle='-',color='k',alpha=0.5)\n",
    "plt.axvline(x=70,linestyle=':',color='k',alpha=0.5)\n",
    "plt.axvline(x=30,linestyle=':',color='k',alpha=0.5)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### di-PLS vs. (k)da-PLS\n",
    "我们现在将拟合无监督的 di-PLS 和 (k)da-PLS 模型，并比较它们在目标域上的表现。我们首先使用 da-PLS 的原始 (primal) 版本，然后讨论核化 (kernelized) 版本。\n",
    "\n",
    "请注意，di-PLS 最小化源域和目标域之间的协方差差异，从而隐含地假设相应的数据集遵循正态分布。另一方面，da-PLS 使用非参数方法来对齐潜在空间中的源分布和目标分布，不对底层数据分布做任何假设。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 3))\n",
    "\n",
    "# 源域 PLS 模型\n",
    "plt.subplot(141)\n",
    "\n",
    "y = np.expand_dims(Cs[:, 0],1)\n",
    "m = dipls(A=2, l=0)\n",
    "l = [0] # 无正则化\n",
    "m.fit(Xs, y, Xs, Xt)\n",
    "b_pls = m.b_\n",
    "\n",
    "# 预测目标域中的分析物\n",
    "yhat_pls = m.predict(Xt)\n",
    "plt.scatter(Ct[:, 0], yhat_pls, color='b', edgecolor='k',alpha=0.75)\n",
    "ax = plt.gca()\n",
    "ax.plot([0, 1], [0, 1], 'k', transform=ax.transAxes)\n",
    "plt.xlabel('测量值')\n",
    "plt.ylabel('预测值')\n",
    "plt.grid(axis='x')\n",
    "plt.title('源域 PLS')\n",
    "\n",
    "# diPLS 模型\n",
    "plt.subplot(142)\n",
    "\n",
    "m_di = dipls(A=2, l=100000)\n",
    "m_di.fit(Xs, y, Xs, Xt)\n",
    "b_dipls = m_di.b_\n",
    "\n",
    "# 预测目标域中的分析物\n",
    "yhat_dipls = m_di.predict(Xt)\n",
    "plt.scatter(Ct[:, 0], yhat_dipls, color='r', edgecolor='k',alpha=0.75)\n",
    "ax = plt.gca()\n",
    "ax.plot([0, 1], [0, 1], 'k', transform=ax.transAxes)\n",
    "plt.xlabel('测量值')\n",
    "plt.ylabel('预测值')\n",
    "plt.grid(axis='x')\n",
    "plt.title('diPLS')\n",
    "\n",
    "# KDA-PLS 模型\n",
    "plt.subplot(143)\n",
    "\n",
    "m_kda = kdapls(A=2, l=1000, target_domain=0, kernel_params={'type': 'primal'})\n",
    "m_kda.fit(Xs, y, Xs, Xt)\n",
    "b_kda = m_kda.coef_\n",
    "\n",
    "# 预测目标域中的分析物\n",
    "yhat_kda = m_kda.predict(Xt)\n",
    "plt.scatter(Ct[:, 0], yhat_kda, color='g', edgecolor='k',alpha=0.75)\n",
    "ax = plt.gca()\n",
    "ax.set_xlim([0, 10])\n",
    "ax.set_ylim([0, 10])\n",
    "ax.plot([0, 1], [0, 1], 'k', transform=ax.transAxes)\n",
    "plt.xlabel('测量值')\n",
    "plt.ylabel('预测值')\n",
    "plt.grid(axis='x')\n",
    "plt.title('daPLS')\n",
    "\n",
    "# 目标域 PLS 模型\n",
    "plt.subplot(144)\n",
    "\n",
    "y = np.expand_dims(Ct[:, 0], 1)\n",
    "m_target = dipls(A=3, l=0)\n",
    "m_target.fit(Xt, y, Xs, Xt)\n",
    "b_target = m_target.b_\n",
    "\n",
    "# 预测目标域中的分析物\n",
    "yhat_target = m_target.predict(Xt)\n",
    "plt.scatter(Ct[:, 0], yhat_target, color='m', edgecolor='k',alpha=0.75)\n",
    "ax = plt.gca()\n",
    "ax.plot([0, 1], [0, 1], 'k', transform=ax.transAxes)\n",
    "plt.xlabel('测量值')\n",
    "plt.ylabel('预测值')\n",
    "plt.grid(axis='x')\n",
    "plt.title('目标域 PLS')\n",
    "\n",
    "plt.suptitle('目标域预测')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以看到，在这种情况下，da-PLS 模型明显优于 di-PLS 模型。为了了解原因，我们接下来将检查这 4 个模型对应的回归系数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制回归系数\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(b_pls, 'b')\n",
    "plt.plot(b_dipls, 'r')\n",
    "plt.plot(b_kda, 'g')\n",
    "plt.plot(b_target, 'm')\n",
    "plt.legend(['源域 PLS','diPLS','daPLS','目标域 PLS'])\n",
    "plt.title('回归系数')\n",
    "plt.xlabel('X-变量')\n",
    "plt.ylabel('系数')\n",
    "plt.axvline(x=50,linestyle='-',color='k',alpha=0.5)\n",
    "plt.axvline(x=70,linestyle=':',color='k',alpha=0.5)\n",
    "plt.axvline(x=30,linestyle=':',color='k',alpha=0.5)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以看到，da-PLS 模型（绿色）的回归系数比 di-PLS 模型（红色）更接近目标域 PLS 模型系数（洋红色）。\n",
    "\n",
    "接下来，我们将 (k)da-PLS 应用于来自以下地址的三聚氰胺 (Melamine) NIR 数据集：https://github.com/RNL1/Melamine-Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 三聚氰胺数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载并读取数据\n",
    "url = \"https://github.com/RNL1/Melamine-Dataset/blob/master/Melamine_Dataset.pkl?raw=true\"\n",
    "data = pd.read_pickle(url)\n",
    "\n",
    "wn1 = data['wn1']\n",
    "wn2 = data['wn2']\n",
    "w = np.hstack((wn1, wn2))\n",
    "\n",
    "Xs = np.hstack((data['R862']['X1'], data['R862']['X2']))\n",
    "Xt = np.hstack((data['R861']['X1'], data['R861']['X2']))\n",
    "\n",
    "ys = data['R862']['Y']\n",
    "yt = data['R861']['Y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 超参数调优\n",
    "我们运行网格搜索来寻找最佳的潜变量 (LVs) 数量和最佳核。请注意，在此步骤中我们仅使用源域数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 调优 LVs 数量和核参数\n",
    "param_grid = {'A': np.arange(1, 20),\n",
    "              'kernel_params': [{'type': 'rbf', 'gamma': 1e-3},\n",
    "                                {'type': 'linear'},\n",
    "                                {'type': 'primal'}]}\n",
    "\n",
    "# 初始化 KDAPLS 模型 \n",
    "m_kdapls = kdapls(target_domain=0)\n",
    "\n",
    "# 使用均方根误差作为评分指标调优 LVs 数量\n",
    "grid_search = GridSearchCV(m_kdapls, param_grid, cv=5, scoring= 'neg_root_mean_squared_error', n_jobs=-1)\n",
    "grid_search.fit(Xs, ys)\n",
    "\n",
    "# 打印发现的最佳参数和最佳评分\n",
    "print(\"发现的最佳参数: \", grid_search.best_params_)\n",
    "\n",
    "# 绘制 MSE 与 LVs 数量的关系图\n",
    "opt_A = grid_search.best_params_['A']-1\n",
    "rmse = -grid_search.cv_results_['mean_test_score']\n",
    "rmse_std = grid_search.cv_results_['std_test_score']\n",
    "#plt.errorbar(param_grid['A'], rmse, yerr=rmse_std, fmt='-o', mec='k', label='CV 误差')\n",
    "rmse_2d = rmse.reshape(len(param_grid[\"kernel_params\"]), len(param_grid[\"A\"]))\n",
    "plt.imshow(rmse_2d, cmap=\"viridis\", aspect=\"auto\")\n",
    "plt.colorbar(label=\"RMSE\")\n",
    "plt.xticks(np.arange(len(param_grid[\"A\"])), param_grid[\"A\"])\n",
    "kernel_labels = [\n",
    "    f\"{kp['type']} (gamma={kp.get('gamma','-')})\" \n",
    "    if 'gamma' in kp else kp['type'] \n",
    "    for kp in param_grid[\"kernel_params\"]\n",
    "]\n",
    "plt.yticks(np.arange(len(kernel_labels)), kernel_labels)\n",
    "plt.xlabel(\"LVs 数量\")\n",
    "plt.ylabel(\"核参数\")\n",
    "plt.title(\"RMSE 热力图\")\n",
    "plt.gca().axvline(opt_A, color='r', linestyle='--', label='最佳 LVs 数量')\n",
    "plt.xlabel('LVs 数量')\n",
    "plt.ylabel('RMSECV')\n",
    "plt.title('RMSECV (源域) vs. LVs 数量')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于这个数据集，使用原始 (primal) da-PLS 模型似乎最合适。核化版本的 da-PLS 在源任务上无法超越原始版本。\n",
    "\n",
    "接下来我们优化正则化参数，该参数决定了源域和目标域之间的对齐程度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 调优正则化参数\n",
    "param_grid = {'l': np.logspace(0, 3, 10)}\n",
    "\n",
    "# 初始化 KDAPLS 模型 \n",
    "m_kdapls = kdapls(target_domain=0, A=12, kernel_params={'type': 'primal'})\n",
    "\n",
    "# 使用均方根误差作为评分指标调优 LVs 数量\n",
    "grid_search = GridSearchCV(m_kdapls, param_grid, cv=5, scoring= 'neg_root_mean_squared_error', n_jobs=-1)\n",
    "grid_search.fit(Xs, ys, **{'xs': Xs, 'xt': Xt}) \n",
    "\n",
    "# 打印发现的最佳参数和最佳评分\n",
    "print(\"发现的最佳参数: \", grid_search.best_params_)\n",
    "\n",
    "# 绘制 MSE 与 l 数量的关系图\n",
    "rmse = -grid_search.cv_results_['mean_test_score']\n",
    "rmse_std = grid_search.cv_results_['std_test_score']/np.sqrt(5)\n",
    "plt.plot(param_grid['l'], rmse, 'o-', mec='k', label='CV 误差')\n",
    "plt.xlabel('正则化参数 l')\n",
    "plt.ylabel('RMSECV (源域)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们希望在不牺牲源域性能的情况下，尽可能选择较大的正则化参数 $l$。这里，我们选择 $l=1000$。\n",
    "\n",
    "现在我们准备拟合最终模型并评估其在目标域上的表现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化 KDAPLS 模型\n",
    "m_kdapls = kdapls(target_domain=0, A=12, l=1000, kernel_params={'type': 'primal'})\n",
    "\n",
    "# 拟合模型\n",
    "m_kdapls.fit(Xs, ys, **{'xs': Xs, 'xt': Xt})\n",
    "\n",
    "# 预测目标域\n",
    "yhat = m_kdapls.predict(Xt)\n",
    "\n",
    "# 绘制预测值与测量值的关系图\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(121)\n",
    "plt.scatter(yt, yhat, color='b', edgecolor='k', alpha=0.75)\n",
    "ax = plt.gca()\n",
    "ax.set_xlim([-10, 60])\n",
    "ax.set_ylim([-10, 60])\n",
    "ax.plot([0, 1], [0, 1], 'k', transform=ax.transAxes)\n",
    "plt.xlabel('测量值')\n",
    "plt.ylabel('预测值')\n",
    "plt.grid(axis='x')\n",
    "plt.title('daPLS')\n",
    "plt.text(0.75, 0.1, f\"RMSEP: {fct.rmse(yhat.T, yt.T):.2f}\", ha='right', va='center', transform=ax.transAxes)\n",
    "\n",
    "# 与 PLS 比较\n",
    "m_kdapls = kdapls(target_domain=0, A=12, l=0, kernel_params={'type': 'primal'})\n",
    "m_kdapls.fit(Xs, ys)\n",
    "yhat = m_kdapls.predict(Xt)\n",
    "plt.subplot(122)\n",
    "plt.scatter(yt, yhat, color='r', edgecolor='k', alpha=0.75)\n",
    "ax = plt.gca()\n",
    "ax.set_xlim([-10, 60])\n",
    "ax.set_ylim([-10, 60])\n",
    "ax.plot([0, 1], [0, 1], 'k', transform=ax.transAxes)\n",
    "plt.xlabel('测量值')\n",
    "plt.ylabel('预测值')\n",
    "plt.grid(axis='x')\n",
    "plt.title('PLS')\n",
    "plt.text(0.75, 0.1, f\"RMSEP: {fct.rmse(yhat.T, yt.T):.2f}\", ha='right', va='center', transform=ax.transAxes)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当应用于目标域时，da-PLS 明显优于 PLS。接下来我们研究它与 di-PLS 相比的表现如何。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diPLS 和 daPLS 的正则化参数\n",
    "l_da = [1e2, 1e3, 1e10]\n",
    "l_di = [1e2, 1e3, 1e10]\n",
    "\n",
    "# 回归系数\n",
    "b_da = {}\n",
    "b_di = {}\n",
    "\n",
    "i = 0\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(3):\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    m_da = kdapls(A=12, l=l_da[i], target_domain=0, kernel_params={'type': 'primal'})\n",
    "    m_da.fit(Xs, ys, Xs, Xt)\n",
    "    yhat_da = m_da.predict(Xt)\n",
    "    plt.scatter(yt, yhat_da, color='b', edgecolor='k', alpha=0.75)\n",
    "    ax = plt.gca()\n",
    "    ax.set_xlim([-20, 80])\n",
    "    ax.set_ylim([-20, 80])\n",
    "    ax.plot([0, 1], [0, 1], 'k', transform=ax.transAxes)\n",
    "    plt.xlabel('测量值')\n",
    "    plt.ylabel('预测值')\n",
    "    plt.grid(axis='x')\n",
    "    plt.title(f\"daPLS (l={l_da[i]:.1e})\")\n",
    "    plt.text(0.75, 0.1, f\"RMSEP: {fct.rmse(yhat_da.T, yt.T):.2f}\", ha='right', va='center', transform=ax.transAxes)\n",
    "    b_da[l_da[i]] = m_da.coef_\n",
    "\n",
    "    plt.subplot(2, 3, i+4)\n",
    "    m_di = dipls(A=12, l=l_di[i])\n",
    "    m_di.fit(Xs, ys, Xs, Xt)\n",
    "    yhat_di = m_di.predict(Xt)\n",
    "    plt.scatter(yt, yhat_di, color='r', edgecolor='k', alpha=0.75)\n",
    "    ax = plt.gca()\n",
    "    ax.set_xlim([-20, 80])\n",
    "    ax.set_ylim([-20, 80])\n",
    "    ax.plot([0, 1], [0, 1], 'k', transform=ax.transAxes)\n",
    "    plt.xlabel('测量值')\n",
    "    plt.ylabel('预测值')\n",
    "    plt.grid(axis='x')\n",
    "    plt.title(f\"diPLS (l={l_di[i]:.1e})\")\n",
    "    plt.text(0.75, 0.1, f\"RMSEP: {fct.rmse(yhat_di.T, yt.T):.2f}\", ha='right', va='center', transform=ax.transAxes)\n",
    "    b_di[l_di[i]] = m_di.b_\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以看到，在正则化参数 $l$ 值较小时，di-PLS 的表现明显更好（左图）。然而，di-PLS 容易产生过拟合，随着我们增加正则化参数，di-PLS 的性能会下降（右图）。另一方面，da-PLS 更加健壮，不会受到过拟合的影响。\n",
    "\n",
    "为了更清楚地看到这一点，我们绘制相应的回归系数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制回归系数\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(121)\n",
    "offset = 0\n",
    "for i, key in enumerate(b_da):\n",
    "    plt.plot(b_da[key] + offset, label=f\"{key:.1e}\")\n",
    "    offset += 500  # 根据需要调整偏移值\n",
    "plt.legend([f\"{key:.1e}\" for key in b_da.keys()])\n",
    "plt.title('daPLS')\n",
    "plt.xlabel('X-变量')\n",
    "plt.ylabel('系数')\n",
    "\n",
    "# 绘制带偏移的 diPLS 系数\n",
    "plt.subplot(122)\n",
    "offset = 0\n",
    "for i, key in enumerate(b_di):\n",
    "    plt.plot(b_di[key] + offset, label=f\"{key:.1e}\")\n",
    "    offset += 500  # 根据需要调整偏移值\n",
    "plt.legend([f\"{key:.1e}\" for key in b_di.keys()])\n",
    "plt.title('diPLS')\n",
    "plt.xlabel('X-变量')\n",
    "plt.ylabel('系数')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以看到，随着正则化参数的增加，di-PLS 系数变得越来越起伏不平。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 多个目标域"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "di-PLS 和 da-PLS 之间另一个值得进行的比较是当我们有多个目标域时。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 源域 (分析物 + 1 种干扰物)\n",
    "n = 50  # 样本数量\n",
    "p = 100 # 变量数量\n",
    "\n",
    "# 生成信号\n",
    "S1 = fct.gengaus(p, 50, 15, 8, 0)  # 分析物\n",
    "S2 = fct.gengaus(p, 70, 10, 10, 0) # 干扰物\n",
    "S = np.vstack([S1,S2])\n",
    "\n",
    "# 分析物浓度\n",
    "Cs = 10*np.random.rand(n,S.shape[0])\n",
    "\n",
    "# 光谱\n",
    "X = Cs@S\n",
    "\n",
    "# 随机噪声\n",
    "noise = 0.005*np.random.rand(n,p)\n",
    "\n",
    "# 源域光谱加上噪声\n",
    "Xs = X# + noise\n",
    "\n",
    "# 目标域 1 (分析物 + 2 种干扰物)\n",
    "S1 = fct.gengaus(p, 50, 15, 8, 0)  # 分析物\n",
    "S2 = fct.gengaus(p, 70, 10, 10, 0) # 干扰物 1\n",
    "S3 = fct.gengaus(p, 30, 10, 10, 0) # 干扰物 2\n",
    "S = np.vstack([S1,S2,S3])\n",
    "\n",
    "# 分析物浓度\n",
    "Ct1 = 10*np.random.rand(n,S.shape[0])\n",
    "\n",
    "# 光谱\n",
    "X = Ct1@S\n",
    "\n",
    "# 随机噪声\n",
    "noise = 0.005*np.random.rand(n,p)\n",
    "\n",
    "# 目标域光谱加上噪声\n",
    "Xt1 = X# + noise\n",
    "\n",
    "# 目标域 2 (分析物 + 3 种干扰物)\n",
    "S1 = fct.gengaus(p, 50, 15, 8, 0)  # 分析物\n",
    "S2 = fct.gengaus(p, 70, 10, 10, 0) # 干扰物 1\n",
    "S3 = fct.gengaus(p, 30, 10, 10, 0) # 干扰物 2\n",
    "S4 = fct.gengaus(p, 75, 75, 150, 0) # 干扰物 3\n",
    "S = np.vstack([S1, S2, S3, S4])\n",
    "\n",
    "# 分析物浓度\n",
    "Ct2 = 10*np.random.rand(n,S.shape[0])\n",
    "\n",
    "# 光谱\n",
    "X = Ct2@S\n",
    "\n",
    "# 随机噪声\n",
    "noise = 0.005*np.random.rand(n,p)\n",
    "\n",
    "# 目标域光谱加上噪声\n",
    "Xt2 = X# + noise\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(211)\n",
    "plt.plot(S1)\n",
    "plt.plot(S2)\n",
    "plt.plot(S3)\n",
    "plt.plot(S4)\n",
    "plt.legend(['分析物','干扰物 1','干扰物 2', '干扰物 3'])\n",
    "plt.title('纯信号')\n",
    "plt.xlabel('X-变量')\n",
    "plt.ylabel('信号')\n",
    "plt.axvline(x=50,linestyle='-',color='k',alpha=0.5)\n",
    "plt.axvline(x=70,linestyle=':',color='k',alpha=0.5)\n",
    "plt.axvline(x=30,linestyle=':',color='k',alpha=0.5)\n",
    "\n",
    "\n",
    "plt.subplot(234)\n",
    "plt.plot(Xs.T, 'b', alpha=0.2)\n",
    "plt.title('源域')\n",
    "plt.xlabel('X-变量')\n",
    "plt.ylabel('信号')\n",
    "\n",
    "plt.subplot(235)\n",
    "plt.plot(Xt1.T, 'r', alpha=0.2)\n",
    "plt.title('目标域 1')\n",
    "plt.xlabel('X-变量')\n",
    "plt.ylabel('信号')\n",
    "\n",
    "plt.subplot(236)\n",
    "plt.plot(Xt2.T, 'g', alpha=0.2)\n",
    "plt.title('目标域 2')\n",
    "plt.xlabel('X-变量')\n",
    "plt.ylabel('信号')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们将拟合一个具有 2 个 LVs 的 da-PLS 模型，并使 $l$ 足够大以对齐源域和目标域。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 准备工作\n",
    "nr_comp = 2                         # 组件数量\n",
    "l = 1e9   # 正则化参数                           \n",
    "target_domains = [Xt1, Xt2]         # 目标域\n",
    "ys = np.expand_dims(Cs[:, 0],1)     # 源域浓度\n",
    "yt1 = np.expand_dims(Ct1[:, 0],1)   # 目标域 1 浓度\n",
    "yt2 = np.expand_dims(Ct2[:, 0],1)   # 目标域 2 浓度\n",
    "\n",
    "# daPLS 模型\n",
    "m_kdapls = kdapls(A=nr_comp, l=l, kernel_params={'type': 'primal'})\n",
    "m_kdapls.fit(Xs, ys, Xs, target_domains)\n",
    "b_dapls = m_kdapls.coef_\n",
    "yhat_daplsT1 = m_kdapls.predict(Xt1)\n",
    "yhat_daplsT2 = m_kdapls.predict(Xt2)\n",
    "\n",
    "error_diplsT1 = fct.rmse(yt1, yhat_daplsT1)\n",
    "error_diplsT2 = fct.rmse(yt2, yhat_daplsT2)\n",
    "print(f\"RMSEP 目标域 1: {error_diplsT1:.2f}\")\n",
    "print(f\"RMSEP 目标域 2: {error_diplsT2:.2f}\")\n",
    "\n",
    "min_ = -5\n",
    "max_ = 15\n",
    "\n",
    "# 绘制\n",
    "plt.figure(figsize=(9, 4))\n",
    "plt.subplot(121)\n",
    "plt.scatter(yt1, yhat_daplsT1, color='m', edgecolor='k',alpha=0.75)\n",
    "plt.plot([min_,max_], [min_,max_], color='k', linestyle=\":\")\n",
    "plt.xlim([min_,max_])\n",
    "plt.ylim([min_,max_])\n",
    "plt.title('目标域 1 的预测')\n",
    "plt.xlabel('测量值')\n",
    "plt.ylabel('预测值')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.scatter(yt2, yhat_daplsT2, color='m', edgecolor='k',alpha=0.75)\n",
    "plt.plot([min_,max_], [min_,max_], color='k', linestyle=\":\")\n",
    "plt.xlim([min_,max_])\n",
    "plt.ylim([min_,max_])\n",
    "plt.title('目标域 2 的预测')\n",
    "plt.xlabel('测量值')\n",
    "plt.ylabel('预测值')\n",
    "plt.suptitle('da-PLS')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如我们所见，生成的（单个 da-PLS）模型在两个目标域上都表现良好。另一方面，对于 mdi-PLS，我们需要指定要为哪个目标域拟合模型（参见 `demo_mdiPLS.ipynb`）。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
